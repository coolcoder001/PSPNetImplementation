{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CrossEntropyLoss2d(nn.Module):\n",
    "\n",
    "    def __init__(self, weight=None,size_average=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.loss = nn.NLLLoss2d(weight,size_average)\n",
    "\n",
    "    def forward(self, outputs, targets):\n",
    "        return self.loss(F.log_softmax(outputs), targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image transformation ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "def colormap(n):\n",
    "    cmap=np.zeros([n, 3]).astype(np.uint8)\n",
    "\n",
    "    for i in np.arange(n):\n",
    "        r, g, b = np.zeros(3)\n",
    "\n",
    "        for j in np.arange(8):\n",
    "            r = r + (1<<(7-j))*((i&(1<<(3*j))) >> (3*j))\n",
    "            g = g + (1<<(7-j))*((i&(1<<(3*j+1))) >> (3*j+1))\n",
    "            b = b + (1<<(7-j))*((i&(1<<(3*j+2))) >> (3*j+2))\n",
    "\n",
    "        cmap[i,:] = np.array([r, g, b])\n",
    "\n",
    "    return cmap\n",
    "\n",
    "class Relabel:\n",
    "\n",
    "    def __init__(self, olabel, nlabel):\n",
    "        self.olabel = olabel\n",
    "        self.nlabel = nlabel\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        assert isinstance(tensor, torch.LongTensor), 'tensor needs to be LongTensor'\n",
    "        tensor[tensor == self.olabel] = self.nlabel\n",
    "        return tensor\n",
    "\n",
    "\n",
    "class ToLabel:\n",
    "\n",
    "    def __call__(self, image):\n",
    "        return torch.from_numpy(np.array(image)).long().unsqueeze(0)\n",
    "\n",
    "\n",
    "class Colorize:\n",
    "\n",
    "    def __init__(self, n=3):\n",
    "        self.cmap = colormap(256)\n",
    "        self.cmap[n] = self.cmap[-1]\n",
    "        self.cmap = torch.from_numpy(self.cmap[:n])\n",
    "\n",
    "    def __call__(self, gray_image):\n",
    "        size = gray_image.size()\n",
    "        color_image = torch.ByteTensor(3, size[1], size[2]).fill_(0)\n",
    "\n",
    "        for label in range(1, len(self.cmap)):\n",
    "            mask = gray_image[0] == label\n",
    "\n",
    "            color_image[0][mask] = self.cmap[label][0]\n",
    "            color_image[1][mask] = self.cmap[label][1]\n",
    "            color_image[2][mask] = self.cmap[label][2]\n",
    "\n",
    "        return color_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loader ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import collections\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import scipy.misc as m\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "from PIL import Image\n",
    "from torch.utils import data\n",
    "\n",
    "\n",
    "class ImageLoader(data.Dataset):\n",
    "    \n",
    "    \n",
    "    def make_dataset(self,dir, set):\n",
    "        images = []\n",
    "        if set == 'train':\n",
    "            fname = os.path.join(dir, 'train_test_split.yaml')\n",
    "        elif set == 'test':\n",
    "            fname = os.path.join(dir, 'train_test_split.yaml')\n",
    "\n",
    "        # read the content of the file\n",
    "        with open(fname,'r') as f:\n",
    "            doc = yaml.load(f)\n",
    "\n",
    "        imagesNum = doc[set]\n",
    "        imageFolderPath = dir + os.sep + 'images' + os.sep\n",
    "        file_list = []\n",
    "        \n",
    "        for x in imagesNum:\n",
    "            item = imageFolderPath + os.sep + str(x)+'_image.png'\n",
    "\n",
    "            width, height = Image.open(open(item,'rb')).size\n",
    "            #print(\"Width ==> \",width,\" Height ==> \",height)\n",
    "            \n",
    "            file_list.append(item)\n",
    "        \n",
    "        self.files[set]=file_list\n",
    "            \n",
    "        return\n",
    "    \n",
    "    def __init__(self, root, split=\"train\", img_size=None,input_transform=None, target_transform=None):\n",
    "        self.root = root\n",
    "        self.split = split\n",
    "        self.img_size = [1296, 966]\n",
    "        \n",
    "        \n",
    "        self.n_classes = 2\n",
    "        self.files = collections.defaultdict(list)\n",
    "        \n",
    "        self.input_transform = input_transform\n",
    "        self.target_transform = target_transform\n",
    "        \n",
    "        self.make_dataset(root,split)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files[self.split])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_name = self.files[self.split][index]\n",
    "                \n",
    "        img_path = img_name\n",
    "        img_name = os.path.split(img_path)[1]\n",
    "        #print(\"Img name ==> \",img_name)\n",
    "        img_num = img_name.split(\"_\")[0]\n",
    "        #print(\"Img num ==> \",img_num)\n",
    "        \n",
    "        lbl_path = self.root + os.sep + 'annotations' + os.sep + img_num +\"_\" + \"annotation.png\"\n",
    "\n",
    "        with open(img_path, 'rb') as f:\n",
    "            image = Image.open(f).convert('RGB')\n",
    "            \n",
    "        \n",
    "        with open(lbl_path, 'rb') as f:\n",
    "            label = Image.open(f).convert('P')\n",
    "            \n",
    "        if self.input_transform is not None:\n",
    "            image = self.input_transform(image)\n",
    "            #print(\"image ==> \",image)\n",
    "            \n",
    "        if self.target_transform is not None:\n",
    "            label = self.target_transform(label)\n",
    "            #print(\"label ==> \",label)\n",
    "            \n",
    "            \n",
    "            \n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Model (PSPNet) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "# from torch.utils import model_zoo\n",
    "from torchvision import models\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class PSPModifierClass(nn.Module):\n",
    "\n",
    "    def __init__(self, in_features, out_features, downsize, upsize=18):\n",
    "        super().__init__()\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            nn.AvgPool2d(downsize, stride=downsize),\n",
    "            nn.Conv2d(in_features, out_features, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_features,momentum=.95),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.UpsamplingBilinear2d(upsize)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.features(x)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class PSPNet(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "\n",
    "        resnet = models.resnet101(pretrained=True)\n",
    "        \n",
    "        self.conv1 = resnet.conv1\n",
    "        self.layer1 = resnet.layer1\n",
    "        self.layer2 = resnet.layer2\n",
    "        self.layer3 = resnet.layer3\n",
    "        self.layer4 = resnet.layer4\n",
    "        \n",
    "        self.avgPool =  nn.AvgPool2d(14, stride=14)\n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                m.stride = 1\n",
    "                m.requires_grad = False\n",
    "            if isinstance(m, nn.BatchNorm2d):\n",
    "                m.requires_grad = False\n",
    "        \n",
    "        \n",
    "        self.layer5a = PSPModifierClass(2048, 512, 60)\n",
    "        self.layer5b = PSPModifierClass(2048, 512, 30)\n",
    "        self.layer5c = PSPModifierClass(2048, 512, 20)\n",
    "        self.layer5d = PSPModifierClass(2048, 512, 10)\n",
    "        \n",
    "        \n",
    "        self.final = nn.Sequential(\n",
    "            #nn.Conv2d(2048, 512, 3, padding=1, bias=False),\n",
    "            \n",
    "            nn.Conv2d(4096, 512, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(512, momentum=.95),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(.1),\n",
    "            nn.Conv2d(512, num_classes, 1)\n",
    "            \n",
    "            #nn.Conv2d(512, num_classes, 2)\n",
    "\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        #print('x', x.size())\n",
    "        \n",
    "        x = self.conv1(x)\n",
    "        #print('conv1', x.size())\n",
    "        \n",
    "        x = self.layer1(x)\n",
    "        #print('layer1', x.size())\n",
    "        \n",
    "        x = self.layer2(x)\n",
    "        #print('layer2', x.size())\n",
    "        \n",
    "        x = self.layer3(x)\n",
    "        #print('layer3', x.size())\n",
    "        \n",
    "        x = self.layer4(x)\n",
    "        #print('layer4', x.size())\n",
    "        \n",
    "        #x=self.down(x)\n",
    "        \n",
    "       \n",
    "        temp_x=self.avgPool(x)\n",
    "        #print('After downsample x ==> ',temp_x.size())\n",
    "\n",
    "        \n",
    "        t5a = self.layer5a(x)\n",
    "        #print('layer5a',t5a.size())\n",
    "        \n",
    "        \n",
    "        t5b = self.layer5b(x)\n",
    "        #print('layer5b',t5b.size())\n",
    "        \n",
    "        t5c = self.layer5c(x)\n",
    "        #print('layer5c',t5c.size())\n",
    "        \n",
    "        t5d = self.layer5d(x)\n",
    "        #print('layer5d',t5d.size())\n",
    "        \n",
    "        \n",
    "        x = self.final(torch.cat([\n",
    "            temp_x,\n",
    "            t5a,\n",
    "            t5b,\n",
    "            t5c,\n",
    "            t5d,\n",
    "        ], 1))\n",
    "        \n",
    "        #print('final', x.size())\n",
    "        \n",
    "        return F.upsample_bilinear(x,[256,256])\n",
    "        #return F.upsample_bilinear(self.final, x.size()[2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization class ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from visdom import Visdom\n",
    "\n",
    "class Dashboard:\n",
    "\n",
    "    def __init__(self, port):\n",
    "        self.vis = Visdom(port=port)\n",
    "\n",
    "    def loss(self, losses, title):\n",
    "        x = np.arange(1, len(losses)+1, 1)\n",
    "\n",
    "        self.vis.line(losses, x, env='loss', opts=dict(title=title))\n",
    "\n",
    "    def image(self, image, title):\n",
    "        if image.is_cuda:\n",
    "            image = image.cpu()\n",
    "        if isinstance(image, Variable):\n",
    "            image = image.data\n",
    "        image = image.numpy()\n",
    "\n",
    "        self.vis.image(image, env='images', opts=dict(title=title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from PIL import Image\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import Compose, CenterCrop, Normalize,Scale,Resize\n",
    "from torchvision.transforms import ToTensor, ToPILImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "NUM_CHANNELS = 3\n",
    "NUM_CLASSES = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "color_transform = Colorize()\n",
    "image_transform = ToPILImage()\n",
    "\n",
    "input_transform = Compose([\n",
    "    CenterCrop(256),\n",
    "    #Resize(136),\n",
    "    ToTensor(),\n",
    "    Normalize([.485, .456, .406], [.229, .224, .225]),\n",
    "])\n",
    "target_transform = Compose([\n",
    "    CenterCrop(256),\n",
    "    #Resize(136),\n",
    "    ToLabel(),\n",
    "    Relabel(255, 2),\n",
    "])\n",
    "\n",
    "\n",
    "# input_transform = Compose([\n",
    "#     #CenterCrop(512),\n",
    "#     Resize(500),\n",
    "#     ToTensor()\n",
    "#     #Normalize([.485, .456, .406], [.229, .224, .225]),\n",
    "# ])\n",
    "# target_transform = Compose([\n",
    "#     #CenterCrop(256),\n",
    "#     Resize(500),\n",
    "#     ToLabel()\n",
    "#     #Relabel(255, 21),\n",
    "# ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing PSPNet ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "model = PSPNet(num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_folder = 'dataset-1.0/'\n",
    "train_dataset = ImageLoader(dataset_folder,split=\"train\",input_transform=input_transform,target_transform=target_transform)\n",
    "test_dataset = ImageLoader(dataset_folder,split=\"test\",input_transform=input_transform,target_transform=target_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x,y=train_dataset.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weight = torch.ones(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weight[2] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_workers=1\n",
    "batch_size=1\n",
    "num_epochs=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainLoader = DataLoader(train_dataset,num_workers=num_workers,batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#criterion = CrossEntropyLoss2d(weight)\n",
    "criterion = CrossEntropyLoss2d(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#optimizer=SGD(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-3)\n",
    "optimizer = SGD(model.parameters(), 1e-3, .9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(len(trainLoader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "board = Dashboard(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(1, num_epochs+1):\n",
    "    epoch_loss = []\n",
    "    iteration=1\n",
    "    for step, (images, labels) in enumerate(trainLoader):\n",
    "        print(\"Iter:\"+str(iteration))\n",
    "        im_arr = np.array(labels)\n",
    "        #print(\"Labels ==> \",np.unique(np.array(labels)))\n",
    "        im_arr[(im_arr!=0) & (im_arr!=15) & (im_arr!=40)] = 0\n",
    "        \n",
    "        # Set to classes\n",
    "        im_arr[im_arr==15] = 1\n",
    "        im_arr[im_arr==40] = 2\n",
    "        #print(np.unique(im_arr))\n",
    "        \n",
    "        iteration=iteration+1\n",
    "        inputs = Variable(images)\n",
    "        targets = Variable(torch.from_numpy(im_arr))\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        optimizer.zero_grad()\n",
    "        #print(\"outputs size ==> \",outputs.size())\n",
    "        \n",
    "        #print(\"outputs[:,0] size ==> \",outputs[:,0].size())\n",
    "        #print(\"targets[:, 0] size ==> \",targets[:, 0].size())\n",
    "\n",
    "\n",
    "        #loss = criterion(outputs, targets[:, 0])\n",
    "        \n",
    "        #print(targets[:,0])\n",
    "        loss = criterion(outputs,targets[:,0])\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss.append(loss.data[0])\n",
    "        \n",
    "        average = sum(epoch_loss) / len(epoch_loss)\n",
    "        \n",
    "        print(\"loss: \"+str(average)+\" epoch: \"+str(epoch)+\", step: \"+str(step))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
