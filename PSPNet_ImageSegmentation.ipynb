{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CrossEntropyLoss2d(nn.Module):\n",
    "\n",
    "    def __init__(self, weight=None,size_average=True):\n",
    "        super().__init__()\n",
    "\n",
    "        self.loss = nn.NLLLoss2d(weight,size_average)\n",
    "\n",
    "    def forward(self, outputs, targets):\n",
    "        return self.loss(F.log_softmax(outputs), targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image transformation ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "class CustomScale(object):\n",
    "    def __init__(self, size, interpolation=Image.NEAREST):\n",
    "        assert isinstance(size, int) or (isinstance(size, collections.Iterable) and len(size) == 2)\n",
    "        self.size = size\n",
    "        self.interpolation = interpolation\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if isinstance(self.size, int):\n",
    "            w, h = img.size\n",
    "            if (w <= h and w == self.size) or (h <= w and h == self.size):\n",
    "                return img\n",
    "            if w < h:\n",
    "                ow = self.size\n",
    "                oh = int(self.size * h / w)\n",
    "                return img.resize((ow, oh), self.interpolation)\n",
    "            else:\n",
    "                oh = self.size\n",
    "                ow = int(self.size * w / h)\n",
    "                return img.resize((ow, oh), self.interpolation)\n",
    "        else:\n",
    "            return img.resize(self.size, self.interpolation)\n",
    "\n",
    "def colormap(n):\n",
    "    cmap=np.zeros([n, 3]).astype(np.uint8)\n",
    "\n",
    "    for i in np.arange(n):\n",
    "        r, g, b = np.zeros(3)\n",
    "\n",
    "        for j in np.arange(8):\n",
    "            r = r + (1<<(7-j))*((i&(1<<(3*j))) >> (3*j))\n",
    "            g = g + (1<<(7-j))*((i&(1<<(3*j+1))) >> (3*j+1))\n",
    "            b = b + (1<<(7-j))*((i&(1<<(3*j+2))) >> (3*j+2))\n",
    "\n",
    "        cmap[i,:] = np.array([r, g, b])\n",
    "\n",
    "    return cmap\n",
    "\n",
    "def uint82bin(n, count=8):\n",
    "    \"\"\"returns the binary of integer n, count refers to amount of bits\"\"\"\n",
    "    return ''.join([str((n >> y) & 1) for y in range(count-1, -1, -1)])\n",
    "\n",
    "def labelcolormap(N):\n",
    "    cmap = np.zeros((N, 3), dtype=np.uint8)\n",
    "    for i in range(N):\n",
    "        r = 0\n",
    "        g = 0\n",
    "        b = 0\n",
    "        id = i\n",
    "        for j in range(7):\n",
    "            str_id = uint82bin(id)\n",
    "            r = r ^ (np.uint8(str_id[-1]) << (7-j))\n",
    "            g = g ^ (np.uint8(str_id[-2]) << (7-j))\n",
    "            b = b ^ (np.uint8(str_id[-3]) << (7-j))\n",
    "            id = id >> 3\n",
    "        cmap[i, 0] = r\n",
    "        cmap[i, 1] = g\n",
    "        cmap[i, 2] = b\n",
    "    return cmap\n",
    "\n",
    "class Relabel:\n",
    "\n",
    "    def __init__(self, olabel, nlabel):\n",
    "        self.olabel = olabel\n",
    "        self.nlabel = nlabel\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        assert isinstance(tensor, torch.LongTensor), 'tensor needs to be LongTensor'\n",
    "        for i in tensor:\n",
    "            i[i == self.olabel] = self.nlabel\n",
    "        return tensor\n",
    "\n",
    "\n",
    "class ToLabel:\n",
    "\n",
    "    def __call__(self, image):\n",
    "        return torch.from_numpy(np.array(image)).long().unsqueeze(0)\n",
    "\n",
    "\n",
    "class Colorize1(object):\n",
    "    def __init__(self, n=3):\n",
    "        self.cmap = labelcolormap(3)\n",
    "        self.cmap = torch.from_numpy(self.cmap[:n])\n",
    "\n",
    "    def __call__(self, gray_image):\n",
    "        size = gray_image.size()\n",
    "        color_image = torch.ByteTensor(size[0], size[1]).fill_(0)\n",
    "\n",
    "        for label in range(0, len(self.cmap)):\n",
    "            mask = (label == gray_image[0]).cpu()\n",
    "            color_image[0][mask] = self.cmap[label][0]\n",
    "            color_image[1][mask] = self.cmap[label][1]\n",
    "            color_image[2][mask] = self.cmap[label][2]\n",
    "\n",
    "        return color_image\n",
    "\n",
    "class Colorize:\n",
    "\n",
    "    def __init__(self, n=3):\n",
    "        #self.cmap = colormap(256)\n",
    "        self.cmap = colormap(136)\n",
    "        self.cmap[n] = self.cmap[-1]\n",
    "        self.cmap = torch.from_numpy(self.cmap[:n])\n",
    "\n",
    "    def __call__(self, gray_image):\n",
    "        size = gray_image.size()\n",
    "        print(\"size of gray image \",size)\n",
    "        #color_image = torch.ByteTensor(3, size[1], size[2]).fill_(0)\n",
    "        \n",
    "        color_image = torch.ByteTensor(3, size[0], size[1]).fill_(0)\n",
    "\n",
    "        for label in range(1, len(self.cmap)):\n",
    "#             mask = gray_image[0] == label\n",
    "\n",
    "#             color_image[0][mask] = self.cmap[label][0]\n",
    "#             color_image[1][mask] = self.cmap[label][1]\n",
    "#             color_image[2][mask] = self.cmap[label][2]\n",
    "            \n",
    "#             mask = (label == gray_image[0]).cpu()\n",
    "            mask = gray_image[0] == label\n",
    "            color_image[0][mask] = self.cmap[label][0]\n",
    "            color_image[1][mask] = self.cmap[label][1]\n",
    "            color_image[2][mask] = self.cmap[label][2]\n",
    "\n",
    "        return color_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loader ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import collections\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import scipy.misc as m\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "from PIL import Image\n",
    "from torch.utils import data\n",
    "\n",
    "\n",
    "class ImageLoader(data.Dataset):\n",
    "    \n",
    "    \n",
    "    def make_dataset(self,dir, set):\n",
    "        images = []\n",
    "        fname = os.path.join(dir, 'train_test_split.yaml')\n",
    "\n",
    "        # read the content of the file\n",
    "        with open(fname,'r') as f:\n",
    "            doc = yaml.load(f)\n",
    "\n",
    "        imagesNum = doc[set]\n",
    "        imageFolderPath = dir + os.sep + 'images' + os.sep\n",
    "        file_list = []\n",
    "        \n",
    "        for x in imagesNum:\n",
    "            #item = imageFolderPath + os.sep + str(x)+'_image.png'\n",
    "            item = imageFolderPath + os.sep + str(x)+'_resize.png'\n",
    "            width, height = Image.open(open(item,'rb')).size\n",
    "            #print(\"Width ==> \",width,\" Height ==> \",height)\n",
    "            \n",
    "            file_list.append(item)\n",
    "        \n",
    "        self.files[set]=file_list\n",
    "            \n",
    "        return\n",
    "    \n",
    "    def __init__(self, root, split=\"train\", img_size=None,input_transform=None, target_transform=None):\n",
    "        self.root = root\n",
    "        self.split = split\n",
    "        self.img_size = [256, 190]\n",
    "        \n",
    "        \n",
    "        self.n_classes = 3\n",
    "        self.files = collections.defaultdict(list)\n",
    "        \n",
    "        self.input_transform = input_transform\n",
    "        self.target_transform = target_transform\n",
    "        \n",
    "        self.make_dataset(root,split)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files[self.split])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_name = self.files[self.split][index]\n",
    "                \n",
    "        img_path = img_name\n",
    "        img_name = os.path.split(img_path)[1]\n",
    "        #print(\"Img name ==> \",img_name)\n",
    "        img_num = img_name.split(\"_\")[0]\n",
    "        #print(\"Img num ==> \",img_num)\n",
    "        \n",
    "        #lbl_path = self.root + os.sep + 'annotations' + os.sep + img_num +\"_\" + \"annotation.png\"\n",
    "        lbl_path = self.root + os.sep + 'annotations' + os.sep + img_num +\"_\" + \"annotation_resize.png\"\n",
    "\n",
    "        with open(img_path, 'rb') as f:\n",
    "            image = Image.open(f).convert('RGB')\n",
    "            \n",
    "        \n",
    "        with open(lbl_path, 'rb') as f:\n",
    "            label = Image.open(f).convert('P')\n",
    "            \n",
    "        if self.input_transform is not None:\n",
    "            image = self.input_transform(image)\n",
    "            \n",
    "        if self.target_transform is not None:\n",
    "            label = self.target_transform(label)\n",
    "            #print(\"label ==> \",label)\n",
    "            \n",
    "            \n",
    "            \n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import math\n",
    "#import torch.utils.model_zoo as model_zoo\n",
    "import torch\n",
    "import numpy as np\n",
    "affine_par = True\n",
    "\n",
    "\n",
    "def outS(i):\n",
    "    i = int(i)\n",
    "    i = (i+1)/2\n",
    "    i = int(np.ceil((i+1)/2.0))\n",
    "    i = (i+1)/2\n",
    "    return i\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"3x3 convolution with padding\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes, affine = affine_par)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes, affine = affine_par)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1,  dilation_ = 1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, stride=stride, bias=False) # change\n",
    "        self.bn1 = nn.BatchNorm2d(planes,affine = affine_par)\n",
    "        for i in self.bn1.parameters():\n",
    "            i.requires_grad = False\n",
    "        \n",
    "        padding = 1\n",
    "        if dilation_ == 2:\n",
    "            padding = 2\n",
    "        elif dilation_ == 4:\n",
    "            padding = 4\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1,\n",
    "                               padding=padding, bias=False, dilation = dilation_)\n",
    "        self.bn2 = nn.BatchNorm2d(planes,affine = affine_par)\n",
    "        \n",
    "        for i in self.bn2.parameters():\n",
    "            i.requires_grad = False\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4, affine = affine_par)\n",
    "        for i in self.bn3.parameters():\n",
    "            i.requires_grad = False\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class Classifier_Module(nn.Module):\n",
    "\n",
    "    def __init__(self,dilation_series,padding_series,NoLabels):\n",
    "        super(Classifier_Module, self).__init__()\n",
    "        self.conv2d_list = nn.ModuleList()\n",
    "        for dilation,padding in zip(dilation_series,padding_series):\n",
    "            self.conv2d_list.append(nn.Conv2d(2048,NoLabels,kernel_size=3,stride=1, padding =padding, dilation = dilation,bias = True))\n",
    "\n",
    "        for m in self.conv2d_list:\n",
    "            m.weight.data.normal_(0, 0.01)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv2d_list[0](x)\n",
    "        for i in range(len(self.conv2d_list)-1):\n",
    "            out += self.conv2d_list[i+1](x)\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers,NoLabels):\n",
    "        self.inplanes = 64\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64,affine = affine_par)\n",
    "        for i in self.bn1.parameters():\n",
    "            i.requires_grad = False\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1, ceil_mode=True) # change\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=1, dilation__ = 2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=1, dilation__ = 4)\n",
    "        self.layer5 = self._make_pred_layer(Classifier_Module, [6,12,18,24],[6,12,18,24],NoLabels)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, 0.01)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "        #        for i in m.parameters():\n",
    "        #            i.requires_grad = False\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1,dilation__ = 1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion or dilation__ == 2 or dilation__ == 4:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion,affine = affine_par),\n",
    "            )\n",
    "        for i in downsample._modules['1'].parameters():\n",
    "            i.requires_grad = False\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride,dilation_=dilation__, downsample = downsample ))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes,dilation_=dilation__))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "    def _make_pred_layer(self,block, dilation_series, padding_series,NoLabels):\n",
    "        return block(dilation_series,padding_series,NoLabels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.layer5(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class MS_Deeplab(nn.Module):\n",
    "    def __init__(self,block,NoLabels):\n",
    "        super(MS_Deeplab,self).__init__()\n",
    "        self.Scale = ResNet(block,[3, 4, 23, 3],NoLabels)   #changed to fix #4 \n",
    "\n",
    "    def forward(self,x):\n",
    "        input_size = x.size()[2]\n",
    "        self.interp1 = nn.UpsamplingBilinear2d(size = (  int(input_size*0.75)+1,  int(input_size*0.75)+1  ))\n",
    "        self.interp2 = nn.UpsamplingBilinear2d(size = (  int(input_size*0.5)+1,   int(input_size*0.5)+1   ))\n",
    "        self.interp3 = nn.UpsamplingBilinear2d(size = (  int(outS(input_size)),   int(outS(input_size))   ))\n",
    "        out = []\n",
    "        x2 = self.interp1(x)\n",
    "        x3 = self.interp2(x)\n",
    "        out.append(self.Scale(x))# for original scale\n",
    "        out.append(self.interp3(self.Scale(x2)))# for 0.75x scale\n",
    "        out.append(self.Scale(x3))# for 0.5x scale\n",
    "\n",
    "\n",
    "        x2Out_interp = out[1]\n",
    "        x3Out_interp = self.interp3(out[2])\n",
    "        temp1 = torch.max(out[0],x2Out_interp)\n",
    "        out.append(torch.max(temp1,x3Out_interp))\n",
    "        return out\n",
    "\n",
    "def Res_Deeplab(NoLabels=3):\n",
    "    model = MS_Deeplab(Bottleneck,NoLabels)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Model (PSPNet) ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torchvision import models\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class PSPModifierClass(nn.Module):\n",
    "\n",
    "    def __init__(self, in_features, out_features, downsize, upsize=18):\n",
    "        super().__init__()\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            nn.AvgPool2d(downsize, stride=downsize),\n",
    "            nn.Conv2d(in_features, out_features, 1, bias=False),\n",
    "            nn.BatchNorm2d(out_features,momentum=.95),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.UpsamplingBilinear2d(upsize)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.features(x)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class PSPNet(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.resnet = MS_Deeplab(Bottleneck,NoLabels=3)\n",
    "\n",
    "        #self.resnet = models.resnet101(pretrained=True)\n",
    "        \n",
    "#         self.conv1 = resnet.conv1\n",
    "#         self.layer1 = resnet.layer1\n",
    "#         self.layer2 = resnet.layer2\n",
    "#         self.layer3 = resnet.layer3\n",
    "#         self.layer4 = resnet.layer4\n",
    "        \n",
    "        self.avgPool =  nn.AvgPool2d(14, stride=14)\n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "#                 m.stride = 1\n",
    "                m.requires_grad = False\n",
    "            if isinstance(m, nn.BatchNorm2d):\n",
    "                m.requires_grad = False\n",
    "                \n",
    "        self.layer5a = PSPModifierClass(3, 5, 18)\n",
    "        self.layer5b = PSPModifierClass(3, 5, 9)\n",
    "        self.layer5c = PSPModifierClass(3, 5, 6)\n",
    "        self.layer5d = PSPModifierClass(3, 5, 3)        \n",
    "        \n",
    "        \n",
    "#         self.layer5a = PSPModifierClass(2048, 512, 60)\n",
    "#         self.layer5b = PSPModifierClass(2048, 512, 30)\n",
    "#         self.layer5c = PSPModifierClass(2048, 512, 20)\n",
    "#         self.layer5d = PSPModifierClass(2048, 512, 10)\n",
    "        \n",
    "        \n",
    "#         self.final = nn.Sequential(\n",
    "#             #nn.Conv2d(2048, 512, 3, padding=1, bias=False),\n",
    "            \n",
    "#             nn.Conv2d(4096, 512, 3, padding=1, bias=False),\n",
    "#             nn.BatchNorm2d(512, momentum=.95),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.Dropout(.1),\n",
    "#             nn.Conv2d(512, num_classes, 1)\n",
    "#         )\n",
    "\n",
    "        self.final = nn.Sequential(\n",
    "            #nn.Conv2d(41, 25, 3, padding=1, bias=False),\n",
    "            nn.Conv2d(23, 25, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(25, momentum=.95),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(.1),\n",
    "            nn.Conv2d(25, num_classes, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x=self.resnet(x)\n",
    "        x=x[0]\n",
    "        print(\"x shape after resnet ===> \",x.shape)\n",
    "        #temp_x = self.avgPool2(x)\n",
    "        #print(\"x shape after temp avg pool ===> \",temp_x.shape)\n",
    "        print(\"self.layer5a(x) shape ==> \",self.layer5a(x).shape)\n",
    "        print(\"self.layer5b(x) shape ==> \",self.layer5b(x).shape)\n",
    "        print(\"self.layer5c(x) shape ==> \",self.layer5c(x).shape)\n",
    "        print(\"self.layer5d(x) shape ==> \",self.layer5d(x).shape)\n",
    "        x = self.final(torch.cat([\n",
    "            x,\n",
    "            self.layer5a(x),\n",
    "            self.layer5b(x),\n",
    "            self.layer5c(x),\n",
    "            self.layer5d(x),\n",
    "        ], 1))\n",
    "        \n",
    "        finalReturn = F.upsample_bilinear(x,136)\n",
    "        print(\"shape of finalReturn \",finalReturn.shape)\n",
    "        return finalReturn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from torch.optim import SGD, Adam\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import Compose, CenterCrop, Normalize,Scale\n",
    "from torchvision.transforms import ToTensor, ToPILImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "NUM_CHANNELS = 3\n",
    "NUM_CLASSES = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_transform = Colorize()\n",
    "image_transform = ToPILImage()\n",
    "\n",
    "input_transform = Compose([\n",
    "    CenterCrop(256),\n",
    "    CustomScale(136),\n",
    "    ToTensor(),\n",
    "    Normalize([.485, .456, .406], [.229, .224, .225])\n",
    "])\n",
    "target_transform = Compose([\n",
    "    CenterCrop(256),\n",
    "    CustomScale(136),\n",
    "    ToLabel(),\n",
    "    Relabel(255, 2),\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializing PSPNet ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "model = PSPNet(num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PSPNet(\n",
       "  (resnet): MS_Deeplab(\n",
       "    (Scale): ResNet(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=True)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (6): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (7): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (8): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (9): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (10): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (11): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (12): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (13): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (14): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (15): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (16): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (17): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (18): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (19): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (20): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (21): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (22): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "      )\n",
       "      (layer5): Classifier_Module(\n",
       "        (conv2d_list): ModuleList(\n",
       "          (0): Conv2d(2048, 3, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))\n",
       "          (1): Conv2d(2048, 3, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12))\n",
       "          (2): Conv2d(2048, 3, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18))\n",
       "          (3): Conv2d(2048, 3, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (avgPool): AvgPool2d(kernel_size=14, stride=14, padding=0)\n",
       "  (layer5a): PSPModifierClass(\n",
       "    (features): Sequential(\n",
       "      (0): AvgPool2d(kernel_size=18, stride=18, padding=0)\n",
       "      (1): Conv2d(3, 5, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (2): BatchNorm2d(5, eps=1e-05, momentum=0.95, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): UpsamplingBilinear2d(size=18, mode=bilinear)\n",
       "    )\n",
       "  )\n",
       "  (layer5b): PSPModifierClass(\n",
       "    (features): Sequential(\n",
       "      (0): AvgPool2d(kernel_size=9, stride=9, padding=0)\n",
       "      (1): Conv2d(3, 5, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (2): BatchNorm2d(5, eps=1e-05, momentum=0.95, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): UpsamplingBilinear2d(size=18, mode=bilinear)\n",
       "    )\n",
       "  )\n",
       "  (layer5c): PSPModifierClass(\n",
       "    (features): Sequential(\n",
       "      (0): AvgPool2d(kernel_size=6, stride=6, padding=0)\n",
       "      (1): Conv2d(3, 5, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (2): BatchNorm2d(5, eps=1e-05, momentum=0.95, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): UpsamplingBilinear2d(size=18, mode=bilinear)\n",
       "    )\n",
       "  )\n",
       "  (layer5d): PSPModifierClass(\n",
       "    (features): Sequential(\n",
       "      (0): AvgPool2d(kernel_size=3, stride=3, padding=0)\n",
       "      (1): Conv2d(3, 5, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (2): BatchNorm2d(5, eps=1e-05, momentum=0.95, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): UpsamplingBilinear2d(size=18, mode=bilinear)\n",
       "    )\n",
       "  )\n",
       "  (final): Sequential(\n",
       "    (0): Conv2d(23, 25, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(25, eps=1e-05, momentum=0.95, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace)\n",
       "    (3): Dropout(p=0.1)\n",
       "    (4): Conv2d(25, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder = 'dataset-1.0/'\n",
    "train_dataset = ImageLoader(dataset_folder,split=\"train\",input_transform=input_transform,target_transform=target_transform)\n",
    "test_dataset = ImageLoader(dataset_folder,split=\"test\",input_transform=input_transform,target_transform=target_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dataset_folder = 'dataset-1.0/'\n",
    "# train_dataset = ImageLoader(dataset_folder,split=\"train\",input_transform=input_transform,target_transform=target_transform)\n",
    "# test_dataset = ImageLoader(dataset_folder,split=\"test\",input_transform=input_transform,target_transform=target_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x,y=train_dataset.__getitem__(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  0,   0,   0,  ...,   0,   0,   0],\n",
       "         [  0,   0,   0,  ...,   0,   0,   0],\n",
       "         [  0,   0,   0,  ...,   0,   0,   0],\n",
       "         ...,\n",
       "         [  0,   0,   0,  ...,   0,   0,   0],\n",
       "         [  0,   0,   0,  ...,   0,   0,   0],\n",
       "         [  0,   0,   0,  ...,   0,   0,   0]]])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weight = torch.ones(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.,  1.,  1.])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weight[0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  1.,  1.])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_workers=2\n",
    "batch_size=5\n",
    "num_epochs=150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainLoader = DataLoader(train_dataset,num_workers=num_workers,batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "testLoader = DataLoader(test_dataset,num_workers=num_workers,batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cs18mtech01004/.local/lib/python3.5/site-packages/torch/nn/modules/loss.py:198: UserWarning: NLLLoss2d has been deprecated. Please use NLLLoss instead as a drop-in replacement and see http://pytorch.org/docs/master/nn.html#torch.nn.NLLLoss for more details.\n",
      "  warnings.warn(\"NLLLoss2d has been deprecated. \"\n"
     ]
    }
   ],
   "source": [
    "criterion = CrossEntropyLoss2d(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#optimizer=SGD(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-3)\n",
    "#optimizer = SGD(model.parameters(), 1e-3, .9)\n",
    "\n",
    "optimizer=SGD(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "print(len(trainLoader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels ==>  [ 0 11 12 13 14 15 16 17 19 22 23 25 28 29 34 40 41]\n",
      "Labels ==>  [ 0 11 12 13 14 15 16 18 19 20 22 23 28 29 30 34 35 40]\n",
      "Labels ==>  [ 0 11 12 13 14 15 16 17 18 19 20 22 23 24 25 28 29 30 34 35 40]\n",
      "Labels ==>  [ 0 11 12 13 14 15 16 22 24 28 34 40]\n",
      "Labels ==>  [ 0 11 12 13 14 15 16 19 20 21 22 23 24 28 30 34 40]\n",
      "Labels ==>  [ 0 11 12 13 14 15 16 18 19 22 28 34 40]\n",
      "Labels ==>  [ 0 11 12 13 14 15 16 18 20 22 23 24 25 28 30 34 35 40]\n",
      "Labels ==>  [ 0 11 12 13 14 15 16 17 18 22 23 28 29 34 40]\n"
     ]
    }
   ],
   "source": [
    "for step, (images, labels) in enumerate(trainLoader):\n",
    "    im_arr = np.array(labels)\n",
    "    print(\"Labels ==> \",np.unique(im_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "avg_loss=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration :1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cs18mtech01004/.local/lib/python3.5/site-packages/torch/nn/modules/upsampling.py:221: UserWarning: nn.UpsamplingBilinear2d is deprecated. Use nn.Upsample instead.\n",
      "  warnings.warn(\"nn.UpsamplingBilinear2d is deprecated. Use nn.Upsample instead.\")\n",
      "/home/cs18mtech01004/.local/lib/python3.5/site-packages/torch/nn/functional.py:1820: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.upsample instead.\n",
      "  warnings.warn(\"nn.functional.upsample_bilinear is deprecated. Use nn.functional.upsample instead.\")\n",
      "/opt/anaconda/lib/python3.5/site-packages/ipykernel_launcher.py:13: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  del sys.path[0]\n",
      "/opt/anaconda/lib/python3.5/site-packages/ipykernel_launcher.py:34: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(1.1726) epoch: 1, step: 0\n",
      "loss: tensor(1.1627) epoch: 1, step: 1\n",
      "loss: tensor(1.1659) epoch: 1, step: 2\n",
      "loss: tensor(1.1662) epoch: 1, step: 3\n",
      "loss: tensor(1.1653) epoch: 1, step: 4\n",
      "loss: tensor(1.1644) epoch: 1, step: 5\n",
      "loss: tensor(1.1656) epoch: 1, step: 6\n",
      "loss: tensor(1.1719) epoch: 1, step: 7\n",
      "Iteration :2\n",
      "loss: tensor(1.1310) epoch: 2, step: 0\n",
      "loss: tensor(1.1336) epoch: 2, step: 1\n",
      "loss: tensor(1.1041) epoch: 2, step: 2\n",
      "loss: tensor(1.1235) epoch: 2, step: 3\n",
      "loss: tensor(1.1159) epoch: 2, step: 4\n",
      "loss: tensor(1.1124) epoch: 2, step: 5\n",
      "loss: tensor(1.0938) epoch: 2, step: 6\n",
      "loss: tensor(1.0984) epoch: 2, step: 7\n",
      "Iteration :3\n",
      "loss: tensor(1.1302) epoch: 3, step: 0\n",
      "loss: tensor(1.0633) epoch: 3, step: 1\n",
      "loss: tensor(1.0742) epoch: 3, step: 2\n",
      "loss: tensor(1.0780) epoch: 3, step: 3\n",
      "loss: tensor(1.0842) epoch: 3, step: 4\n",
      "loss: tensor(1.0854) epoch: 3, step: 5\n",
      "loss: tensor(1.0771) epoch: 3, step: 6\n",
      "loss: tensor(1.0770) epoch: 3, step: 7\n",
      "Iteration :4\n",
      "loss: tensor(0.9840) epoch: 4, step: 0\n",
      "loss: tensor(1.0200) epoch: 4, step: 1\n",
      "loss: tensor(1.0298) epoch: 4, step: 2\n",
      "loss: tensor(1.0167) epoch: 4, step: 3\n",
      "loss: tensor(1.0365) epoch: 4, step: 4\n",
      "loss: tensor(1.0323) epoch: 4, step: 5\n",
      "loss: tensor(1.0371) epoch: 4, step: 6\n",
      "loss: tensor(1.0404) epoch: 4, step: 7\n",
      "Iteration :5\n",
      "loss: tensor(1.0316) epoch: 5, step: 0\n",
      "loss: tensor(1.0150) epoch: 5, step: 1\n",
      "loss: tensor(1.0111) epoch: 5, step: 2\n",
      "loss: tensor(1.0232) epoch: 5, step: 3\n",
      "loss: tensor(1.0241) epoch: 5, step: 4\n",
      "loss: tensor(1.0181) epoch: 5, step: 5\n",
      "loss: tensor(1.0099) epoch: 5, step: 6\n",
      "loss: tensor(0.9963) epoch: 5, step: 7\n",
      "Iteration :6\n",
      "loss: tensor(1.0472) epoch: 6, step: 0\n",
      "loss: tensor(1.0228) epoch: 6, step: 1\n",
      "loss: tensor(1.0098) epoch: 6, step: 2\n",
      "loss: tensor(0.9922) epoch: 6, step: 3\n",
      "loss: tensor(0.9673) epoch: 6, step: 4\n",
      "loss: tensor(0.9751) epoch: 6, step: 5\n",
      "loss: tensor(0.9733) epoch: 6, step: 6\n",
      "loss: tensor(0.9754) epoch: 6, step: 7\n",
      "Iteration :7\n",
      "loss: tensor(1.0252) epoch: 7, step: 0\n",
      "loss: tensor(0.9779) epoch: 7, step: 1\n",
      "loss: tensor(0.9587) epoch: 7, step: 2\n",
      "loss: tensor(0.9630) epoch: 7, step: 3\n",
      "loss: tensor(0.9623) epoch: 7, step: 4\n",
      "loss: tensor(0.9453) epoch: 7, step: 5\n",
      "loss: tensor(0.9533) epoch: 7, step: 6\n",
      "loss: tensor(0.9612) epoch: 7, step: 7\n",
      "Iteration :8\n",
      "loss: tensor(0.9158) epoch: 8, step: 0\n",
      "loss: tensor(0.9153) epoch: 8, step: 1\n",
      "loss: tensor(0.9150) epoch: 8, step: 2\n",
      "loss: tensor(0.9136) epoch: 8, step: 3\n",
      "loss: tensor(0.9433) epoch: 8, step: 4\n",
      "loss: tensor(0.9564) epoch: 8, step: 5\n",
      "loss: tensor(0.9520) epoch: 8, step: 6\n",
      "loss: tensor(0.9358) epoch: 8, step: 7\n",
      "Iteration :9\n",
      "loss: tensor(0.8560) epoch: 9, step: 0\n",
      "loss: tensor(0.8752) epoch: 9, step: 1\n",
      "loss: tensor(0.9032) epoch: 9, step: 2\n",
      "loss: tensor(0.9044) epoch: 9, step: 3\n",
      "loss: tensor(0.8850) epoch: 9, step: 4\n",
      "loss: tensor(0.8863) epoch: 9, step: 5\n",
      "loss: tensor(0.8797) epoch: 9, step: 6\n",
      "loss: tensor(0.8870) epoch: 9, step: 7\n",
      "Iteration :10\n",
      "loss: tensor(0.8966) epoch: 10, step: 0\n",
      "loss: tensor(0.8951) epoch: 10, step: 1\n",
      "loss: tensor(0.8726) epoch: 10, step: 2\n",
      "loss: tensor(0.8599) epoch: 10, step: 3\n",
      "loss: tensor(0.8616) epoch: 10, step: 4\n",
      "loss: tensor(0.8634) epoch: 10, step: 5\n",
      "loss: tensor(0.8551) epoch: 10, step: 6\n",
      "loss: tensor(0.8535) epoch: 10, step: 7\n",
      "Iteration :11\n",
      "loss: tensor(0.8628) epoch: 11, step: 0\n",
      "loss: tensor(0.8392) epoch: 11, step: 1\n",
      "loss: tensor(0.8498) epoch: 11, step: 2\n",
      "loss: tensor(0.8491) epoch: 11, step: 3\n",
      "loss: tensor(0.8578) epoch: 11, step: 4\n",
      "loss: tensor(0.8564) epoch: 11, step: 5\n",
      "loss: tensor(0.8616) epoch: 11, step: 6\n",
      "loss: tensor(0.8485) epoch: 11, step: 7\n",
      "Iteration :12\n",
      "loss: tensor(0.7418) epoch: 12, step: 0\n",
      "loss: tensor(0.7723) epoch: 12, step: 1\n",
      "loss: tensor(0.7880) epoch: 12, step: 2\n",
      "loss: tensor(0.8118) epoch: 12, step: 3\n",
      "loss: tensor(0.7952) epoch: 12, step: 4\n",
      "loss: tensor(0.8041) epoch: 12, step: 5\n",
      "loss: tensor(0.7977) epoch: 12, step: 6\n",
      "loss: tensor(0.8084) epoch: 12, step: 7\n",
      "Iteration :13\n",
      "loss: tensor(0.8497) epoch: 13, step: 0\n",
      "loss: tensor(0.8510) epoch: 13, step: 1\n",
      "loss: tensor(0.8544) epoch: 13, step: 2\n",
      "loss: tensor(0.8556) epoch: 13, step: 3\n",
      "loss: tensor(0.8435) epoch: 13, step: 4\n",
      "loss: tensor(0.8316) epoch: 13, step: 5\n",
      "loss: tensor(0.8227) epoch: 13, step: 6\n",
      "loss: tensor(0.8234) epoch: 13, step: 7\n",
      "Iteration :14\n",
      "loss: tensor(0.6809) epoch: 14, step: 0\n",
      "loss: tensor(0.7249) epoch: 14, step: 1\n",
      "loss: tensor(0.7261) epoch: 14, step: 2\n",
      "loss: tensor(0.7447) epoch: 14, step: 3\n",
      "loss: tensor(0.7690) epoch: 14, step: 4\n",
      "loss: tensor(0.7709) epoch: 14, step: 5\n",
      "loss: tensor(0.7650) epoch: 14, step: 6\n",
      "loss: tensor(0.7719) epoch: 14, step: 7\n",
      "Iteration :15\n",
      "loss: tensor(0.6894) epoch: 15, step: 0\n",
      "loss: tensor(0.7356) epoch: 15, step: 1\n",
      "loss: tensor(0.7426) epoch: 15, step: 2\n",
      "loss: tensor(0.7400) epoch: 15, step: 3\n",
      "loss: tensor(0.7582) epoch: 15, step: 4\n",
      "loss: tensor(0.7591) epoch: 15, step: 5\n",
      "loss: tensor(0.7715) epoch: 15, step: 6\n",
      "loss: tensor(0.7682) epoch: 15, step: 7\n",
      "Iteration :16\n",
      "loss: tensor(0.7650) epoch: 16, step: 0\n",
      "loss: tensor(0.7254) epoch: 16, step: 1\n",
      "loss: tensor(0.7191) epoch: 16, step: 2\n",
      "loss: tensor(0.7232) epoch: 16, step: 3\n",
      "loss: tensor(0.7047) epoch: 16, step: 4\n",
      "loss: tensor(0.7232) epoch: 16, step: 5\n",
      "loss: tensor(0.7243) epoch: 16, step: 6\n",
      "loss: tensor(0.7182) epoch: 16, step: 7\n",
      "Iteration :17\n",
      "loss: tensor(0.7432) epoch: 17, step: 0\n",
      "loss: tensor(0.7244) epoch: 17, step: 1\n",
      "loss: tensor(0.6864) epoch: 17, step: 2\n",
      "loss: tensor(0.6709) epoch: 17, step: 3\n",
      "loss: tensor(0.7131) epoch: 17, step: 4\n",
      "loss: tensor(0.7107) epoch: 17, step: 5\n",
      "loss: tensor(0.7193) epoch: 17, step: 6\n",
      "loss: tensor(0.7237) epoch: 17, step: 7\n",
      "Iteration :18\n",
      "loss: tensor(0.7328) epoch: 18, step: 0\n",
      "loss: tensor(0.7001) epoch: 18, step: 1\n",
      "loss: tensor(0.6790) epoch: 18, step: 2\n",
      "loss: tensor(0.7008) epoch: 18, step: 3\n",
      "loss: tensor(0.7005) epoch: 18, step: 4\n",
      "loss: tensor(0.6896) epoch: 18, step: 5\n",
      "loss: tensor(0.6823) epoch: 18, step: 6\n",
      "loss: tensor(0.6781) epoch: 18, step: 7\n",
      "Iteration :19\n",
      "loss: tensor(0.6435) epoch: 19, step: 0\n",
      "loss: tensor(0.7328) epoch: 19, step: 1\n",
      "loss: tensor(0.6890) epoch: 19, step: 2\n",
      "loss: tensor(0.6713) epoch: 19, step: 3\n",
      "loss: tensor(0.6795) epoch: 19, step: 4\n",
      "loss: tensor(0.6834) epoch: 19, step: 5\n",
      "loss: tensor(0.6812) epoch: 19, step: 6\n",
      "loss: tensor(0.6851) epoch: 19, step: 7\n",
      "Iteration :20\n",
      "loss: tensor(0.6150) epoch: 20, step: 0\n",
      "loss: tensor(0.6363) epoch: 20, step: 1\n",
      "loss: tensor(0.6275) epoch: 20, step: 2\n",
      "loss: tensor(0.6274) epoch: 20, step: 3\n",
      "loss: tensor(0.6261) epoch: 20, step: 4\n",
      "loss: tensor(0.6139) epoch: 20, step: 5\n",
      "loss: tensor(0.6248) epoch: 20, step: 6\n",
      "loss: tensor(0.6307) epoch: 20, step: 7\n",
      "Iteration :21\n",
      "loss: tensor(0.6588) epoch: 21, step: 0\n",
      "loss: tensor(0.6570) epoch: 21, step: 1\n",
      "loss: tensor(0.6431) epoch: 21, step: 2\n",
      "loss: tensor(0.6544) epoch: 21, step: 3\n",
      "loss: tensor(0.6612) epoch: 21, step: 4\n",
      "loss: tensor(0.6418) epoch: 21, step: 5\n",
      "loss: tensor(0.6582) epoch: 21, step: 6\n",
      "loss: tensor(0.6568) epoch: 21, step: 7\n",
      "Iteration :22\n",
      "loss: tensor(0.7793) epoch: 22, step: 0\n",
      "loss: tensor(0.6954) epoch: 22, step: 1\n",
      "loss: tensor(0.6628) epoch: 22, step: 2\n",
      "loss: tensor(0.6664) epoch: 22, step: 3\n",
      "loss: tensor(0.6688) epoch: 22, step: 4\n",
      "loss: tensor(0.6615) epoch: 22, step: 5\n",
      "loss: tensor(0.6523) epoch: 22, step: 6\n",
      "loss: tensor(0.6473) epoch: 22, step: 7\n",
      "Iteration :23\n",
      "loss: tensor(0.5987) epoch: 23, step: 0\n",
      "loss: tensor(0.6451) epoch: 23, step: 1\n",
      "loss: tensor(0.6532) epoch: 23, step: 2\n",
      "loss: tensor(0.6190) epoch: 23, step: 3\n",
      "loss: tensor(0.6035) epoch: 23, step: 4\n",
      "loss: tensor(0.5984) epoch: 23, step: 5\n",
      "loss: tensor(0.5937) epoch: 23, step: 6\n",
      "loss: tensor(0.5965) epoch: 23, step: 7\n",
      "Iteration :24\n",
      "loss: tensor(0.5727) epoch: 24, step: 0\n",
      "loss: tensor(0.5711) epoch: 24, step: 1\n",
      "loss: tensor(0.6163) epoch: 24, step: 2\n",
      "loss: tensor(0.5839) epoch: 24, step: 3\n",
      "loss: tensor(0.5907) epoch: 24, step: 4\n",
      "loss: tensor(0.5892) epoch: 24, step: 5\n",
      "loss: tensor(0.5835) epoch: 24, step: 6\n",
      "loss: tensor(0.5820) epoch: 24, step: 7\n",
      "Iteration :25\n",
      "loss: tensor(0.5383) epoch: 25, step: 0\n",
      "loss: tensor(0.5499) epoch: 25, step: 1\n",
      "loss: tensor(0.5287) epoch: 25, step: 2\n",
      "loss: tensor(0.5679) epoch: 25, step: 3\n",
      "loss: tensor(0.5766) epoch: 25, step: 4\n",
      "loss: tensor(0.5700) epoch: 25, step: 5\n",
      "loss: tensor(0.5673) epoch: 25, step: 6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0.5709) epoch: 25, step: 7\n",
      "Iteration :26\n",
      "loss: tensor(0.5750) epoch: 26, step: 0\n",
      "loss: tensor(0.5745) epoch: 26, step: 1\n",
      "loss: tensor(0.5516) epoch: 26, step: 2\n",
      "loss: tensor(0.5410) epoch: 26, step: 3\n",
      "loss: tensor(0.5597) epoch: 26, step: 4\n",
      "loss: tensor(0.5665) epoch: 26, step: 5\n",
      "loss: tensor(0.5646) epoch: 26, step: 6\n",
      "loss: tensor(0.5604) epoch: 26, step: 7\n",
      "Iteration :27\n",
      "loss: tensor(0.5753) epoch: 27, step: 0\n",
      "loss: tensor(0.5814) epoch: 27, step: 1\n",
      "loss: tensor(0.5399) epoch: 27, step: 2\n",
      "loss: tensor(0.5448) epoch: 27, step: 3\n",
      "loss: tensor(0.5427) epoch: 27, step: 4\n",
      "loss: tensor(0.5366) epoch: 27, step: 5\n",
      "loss: tensor(0.5410) epoch: 27, step: 6\n",
      "loss: tensor(0.5544) epoch: 27, step: 7\n",
      "Iteration :28\n",
      "loss: tensor(0.5016) epoch: 28, step: 0\n",
      "loss: tensor(0.4762) epoch: 28, step: 1\n",
      "loss: tensor(0.5038) epoch: 28, step: 2\n",
      "loss: tensor(0.5118) epoch: 28, step: 3\n",
      "loss: tensor(0.5178) epoch: 28, step: 4\n",
      "loss: tensor(0.5153) epoch: 28, step: 5\n",
      "loss: tensor(0.5094) epoch: 28, step: 6\n",
      "loss: tensor(0.5065) epoch: 28, step: 7\n",
      "Iteration :29\n",
      "loss: tensor(0.5670) epoch: 29, step: 0\n",
      "loss: tensor(0.6031) epoch: 29, step: 1\n",
      "loss: tensor(0.5623) epoch: 29, step: 2\n",
      "loss: tensor(0.5433) epoch: 29, step: 3\n",
      "loss: tensor(0.5389) epoch: 29, step: 4\n",
      "loss: tensor(0.5211) epoch: 29, step: 5\n",
      "loss: tensor(0.5162) epoch: 29, step: 6\n",
      "loss: tensor(0.5233) epoch: 29, step: 7\n",
      "Iteration :30\n",
      "loss: tensor(0.3895) epoch: 30, step: 0\n",
      "loss: tensor(0.4331) epoch: 30, step: 1\n",
      "loss: tensor(0.4707) epoch: 30, step: 2\n",
      "loss: tensor(0.4911) epoch: 30, step: 3\n",
      "loss: tensor(0.4915) epoch: 30, step: 4\n",
      "loss: tensor(0.5111) epoch: 30, step: 5\n",
      "loss: tensor(0.5178) epoch: 30, step: 6\n",
      "loss: tensor(0.5167) epoch: 30, step: 7\n",
      "Iteration :31\n",
      "loss: tensor(0.5387) epoch: 31, step: 0\n",
      "loss: tensor(0.5152) epoch: 31, step: 1\n",
      "loss: tensor(0.5012) epoch: 31, step: 2\n",
      "loss: tensor(0.4858) epoch: 31, step: 3\n",
      "loss: tensor(0.5174) epoch: 31, step: 4\n",
      "loss: tensor(0.5286) epoch: 31, step: 5\n",
      "loss: tensor(0.5252) epoch: 31, step: 6\n",
      "loss: tensor(0.5166) epoch: 31, step: 7\n",
      "Iteration :32\n",
      "loss: tensor(0.4484) epoch: 32, step: 0\n",
      "loss: tensor(0.4595) epoch: 32, step: 1\n",
      "loss: tensor(0.4769) epoch: 32, step: 2\n",
      "loss: tensor(0.4945) epoch: 32, step: 3\n",
      "loss: tensor(0.4945) epoch: 32, step: 4\n",
      "loss: tensor(0.4946) epoch: 32, step: 5\n",
      "loss: tensor(0.4872) epoch: 32, step: 6\n",
      "loss: tensor(0.4840) epoch: 32, step: 7\n",
      "Iteration :33\n",
      "loss: tensor(0.4448) epoch: 33, step: 0\n",
      "loss: tensor(0.4412) epoch: 33, step: 1\n",
      "loss: tensor(0.5902) epoch: 33, step: 2\n",
      "loss: tensor(0.5651) epoch: 33, step: 3\n",
      "loss: tensor(0.5308) epoch: 33, step: 4\n",
      "loss: tensor(0.5306) epoch: 33, step: 5\n",
      "loss: tensor(0.5293) epoch: 33, step: 6\n",
      "loss: tensor(0.5225) epoch: 33, step: 7\n",
      "Iteration :34\n",
      "loss: tensor(0.4659) epoch: 34, step: 0\n",
      "loss: tensor(0.4617) epoch: 34, step: 1\n",
      "loss: tensor(0.4956) epoch: 34, step: 2\n",
      "loss: tensor(0.4935) epoch: 34, step: 3\n",
      "loss: tensor(0.4822) epoch: 34, step: 4\n",
      "loss: tensor(0.4837) epoch: 34, step: 5\n",
      "loss: tensor(0.4827) epoch: 34, step: 6\n",
      "loss: tensor(0.4740) epoch: 34, step: 7\n",
      "Iteration :35\n",
      "loss: tensor(0.4687) epoch: 35, step: 0\n",
      "loss: tensor(0.4214) epoch: 35, step: 1\n",
      "loss: tensor(0.4325) epoch: 35, step: 2\n",
      "loss: tensor(0.4391) epoch: 35, step: 3\n",
      "loss: tensor(0.4257) epoch: 35, step: 4\n",
      "loss: tensor(0.4377) epoch: 35, step: 5\n",
      "loss: tensor(0.4452) epoch: 35, step: 6\n",
      "loss: tensor(0.4427) epoch: 35, step: 7\n",
      "Iteration :36\n",
      "loss: tensor(0.4342) epoch: 36, step: 0\n",
      "loss: tensor(0.4833) epoch: 36, step: 1\n",
      "loss: tensor(0.4675) epoch: 36, step: 2\n",
      "loss: tensor(0.4627) epoch: 36, step: 3\n",
      "loss: tensor(0.4475) epoch: 36, step: 4\n",
      "loss: tensor(0.4347) epoch: 36, step: 5\n",
      "loss: tensor(0.4472) epoch: 36, step: 6\n",
      "loss: tensor(0.4487) epoch: 36, step: 7\n",
      "Iteration :37\n",
      "loss: tensor(0.4018) epoch: 37, step: 0\n",
      "loss: tensor(0.4198) epoch: 37, step: 1\n",
      "loss: tensor(0.4116) epoch: 37, step: 2\n",
      "loss: tensor(0.4110) epoch: 37, step: 3\n",
      "loss: tensor(0.4399) epoch: 37, step: 4\n",
      "loss: tensor(0.4385) epoch: 37, step: 5\n",
      "loss: tensor(0.4689) epoch: 37, step: 6\n",
      "loss: tensor(0.4663) epoch: 37, step: 7\n",
      "Iteration :38\n",
      "loss: tensor(0.4300) epoch: 38, step: 0\n",
      "loss: tensor(0.4450) epoch: 38, step: 1\n",
      "loss: tensor(0.4356) epoch: 38, step: 2\n",
      "loss: tensor(0.4280) epoch: 38, step: 3\n",
      "loss: tensor(0.4184) epoch: 38, step: 4\n",
      "loss: tensor(0.4153) epoch: 38, step: 5\n",
      "loss: tensor(0.4193) epoch: 38, step: 6\n",
      "loss: tensor(0.4157) epoch: 38, step: 7\n",
      "Iteration :39\n",
      "loss: tensor(0.4058) epoch: 39, step: 0\n",
      "loss: tensor(0.4171) epoch: 39, step: 1\n",
      "loss: tensor(0.4090) epoch: 39, step: 2\n",
      "loss: tensor(0.4137) epoch: 39, step: 3\n",
      "loss: tensor(0.4485) epoch: 39, step: 4\n",
      "loss: tensor(0.4390) epoch: 39, step: 5\n",
      "loss: tensor(0.4347) epoch: 39, step: 6\n",
      "loss: tensor(0.4216) epoch: 39, step: 7\n",
      "Iteration :40\n",
      "loss: tensor(0.3882) epoch: 40, step: 0\n",
      "loss: tensor(0.3861) epoch: 40, step: 1\n",
      "loss: tensor(0.3910) epoch: 40, step: 2\n",
      "loss: tensor(0.4029) epoch: 40, step: 3\n",
      "loss: tensor(0.4048) epoch: 40, step: 4\n",
      "loss: tensor(0.3990) epoch: 40, step: 5\n",
      "loss: tensor(0.4103) epoch: 40, step: 6\n",
      "loss: tensor(0.4215) epoch: 40, step: 7\n",
      "Iteration :41\n",
      "loss: tensor(0.3300) epoch: 41, step: 0\n",
      "loss: tensor(0.3447) epoch: 41, step: 1\n",
      "loss: tensor(0.3574) epoch: 41, step: 2\n",
      "loss: tensor(0.3517) epoch: 41, step: 3\n",
      "loss: tensor(0.3736) epoch: 41, step: 4\n",
      "loss: tensor(0.3904) epoch: 41, step: 5\n",
      "loss: tensor(0.3953) epoch: 41, step: 6\n",
      "loss: tensor(0.3970) epoch: 41, step: 7\n",
      "Iteration :42\n",
      "loss: tensor(0.3969) epoch: 42, step: 0\n",
      "loss: tensor(0.3556) epoch: 42, step: 1\n",
      "loss: tensor(0.4695) epoch: 42, step: 2\n",
      "loss: tensor(0.4562) epoch: 42, step: 3\n",
      "loss: tensor(0.4470) epoch: 42, step: 4\n",
      "loss: tensor(0.4427) epoch: 42, step: 5\n",
      "loss: tensor(0.4386) epoch: 42, step: 6\n",
      "loss: tensor(0.4313) epoch: 42, step: 7\n",
      "Iteration :43\n",
      "loss: tensor(0.3613) epoch: 43, step: 0\n",
      "loss: tensor(0.3477) epoch: 43, step: 1\n",
      "loss: tensor(0.3633) epoch: 43, step: 2\n",
      "loss: tensor(0.4201) epoch: 43, step: 3\n",
      "loss: tensor(0.4183) epoch: 43, step: 4\n",
      "loss: tensor(0.4092) epoch: 43, step: 5\n",
      "loss: tensor(0.4082) epoch: 43, step: 6\n",
      "loss: tensor(0.4056) epoch: 43, step: 7\n",
      "Iteration :44\n",
      "loss: tensor(0.3461) epoch: 44, step: 0\n",
      "loss: tensor(0.3836) epoch: 44, step: 1\n",
      "loss: tensor(0.3787) epoch: 44, step: 2\n",
      "loss: tensor(0.3708) epoch: 44, step: 3\n",
      "loss: tensor(0.3925) epoch: 44, step: 4\n",
      "loss: tensor(0.4052) epoch: 44, step: 5\n",
      "loss: tensor(0.4092) epoch: 44, step: 6\n",
      "loss: tensor(0.3963) epoch: 44, step: 7\n",
      "Iteration :45\n",
      "loss: tensor(0.3860) epoch: 45, step: 0\n",
      "loss: tensor(0.3626) epoch: 45, step: 1\n",
      "loss: tensor(0.3678) epoch: 45, step: 2\n",
      "loss: tensor(0.3696) epoch: 45, step: 3\n",
      "loss: tensor(0.3767) epoch: 45, step: 4\n",
      "loss: tensor(0.3805) epoch: 45, step: 5\n",
      "loss: tensor(0.3937) epoch: 45, step: 6\n",
      "loss: tensor(0.3840) epoch: 45, step: 7\n",
      "Iteration :46\n",
      "loss: tensor(0.3444) epoch: 46, step: 0\n",
      "loss: tensor(0.3624) epoch: 46, step: 1\n",
      "loss: tensor(0.4086) epoch: 46, step: 2\n",
      "loss: tensor(0.4253) epoch: 46, step: 3\n",
      "loss: tensor(0.4362) epoch: 46, step: 4\n",
      "loss: tensor(0.4245) epoch: 46, step: 5\n",
      "loss: tensor(0.4197) epoch: 46, step: 6\n",
      "loss: tensor(0.4111) epoch: 46, step: 7\n",
      "Iteration :47\n",
      "loss: tensor(0.3886) epoch: 47, step: 0\n",
      "loss: tensor(0.3627) epoch: 47, step: 1\n",
      "loss: tensor(0.3464) epoch: 47, step: 2\n",
      "loss: tensor(0.3485) epoch: 47, step: 3\n",
      "loss: tensor(0.3531) epoch: 47, step: 4\n",
      "loss: tensor(0.3744) epoch: 47, step: 5\n",
      "loss: tensor(0.3745) epoch: 47, step: 6\n",
      "loss: tensor(0.3748) epoch: 47, step: 7\n",
      "Iteration :48\n",
      "loss: tensor(0.3546) epoch: 48, step: 0\n",
      "loss: tensor(0.4447) epoch: 48, step: 1\n",
      "loss: tensor(0.4295) epoch: 48, step: 2\n",
      "loss: tensor(0.4109) epoch: 48, step: 3\n",
      "loss: tensor(0.3921) epoch: 48, step: 4\n",
      "loss: tensor(0.3809) epoch: 48, step: 5\n",
      "loss: tensor(0.3723) epoch: 48, step: 6\n",
      "loss: tensor(0.3762) epoch: 48, step: 7\n",
      "Iteration :49\n",
      "loss: tensor(0.3628) epoch: 49, step: 0\n",
      "loss: tensor(0.3514) epoch: 49, step: 1\n",
      "loss: tensor(0.3339) epoch: 49, step: 2\n",
      "loss: tensor(0.3157) epoch: 49, step: 3\n",
      "loss: tensor(0.3242) epoch: 49, step: 4\n",
      "loss: tensor(0.3455) epoch: 49, step: 5\n",
      "loss: tensor(0.3468) epoch: 49, step: 6\n",
      "loss: tensor(0.3501) epoch: 49, step: 7\n",
      "Iteration :50\n",
      "loss: tensor(0.3312) epoch: 50, step: 0\n",
      "loss: tensor(0.3158) epoch: 50, step: 1\n",
      "loss: tensor(0.3160) epoch: 50, step: 2\n",
      "loss: tensor(0.3233) epoch: 50, step: 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0.3311) epoch: 50, step: 4\n",
      "loss: tensor(0.3364) epoch: 50, step: 5\n",
      "loss: tensor(0.3282) epoch: 50, step: 6\n",
      "loss: tensor(0.3196) epoch: 50, step: 7\n",
      "Iteration :51\n",
      "loss: tensor(0.2518) epoch: 51, step: 0\n",
      "loss: tensor(0.3291) epoch: 51, step: 1\n",
      "loss: tensor(0.3388) epoch: 51, step: 2\n",
      "loss: tensor(0.3470) epoch: 51, step: 3\n",
      "loss: tensor(0.3493) epoch: 51, step: 4\n",
      "loss: tensor(0.3512) epoch: 51, step: 5\n",
      "loss: tensor(0.3491) epoch: 51, step: 6\n",
      "loss: tensor(0.3448) epoch: 51, step: 7\n",
      "Iteration :52\n",
      "loss: tensor(0.3116) epoch: 52, step: 0\n",
      "loss: tensor(0.2840) epoch: 52, step: 1\n",
      "loss: tensor(0.2898) epoch: 52, step: 2\n",
      "loss: tensor(0.2994) epoch: 52, step: 3\n",
      "loss: tensor(0.3310) epoch: 52, step: 4\n",
      "loss: tensor(0.3321) epoch: 52, step: 5\n",
      "loss: tensor(0.3264) epoch: 52, step: 6\n",
      "loss: tensor(0.3291) epoch: 52, step: 7\n",
      "Iteration :53\n",
      "loss: tensor(0.4318) epoch: 53, step: 0\n",
      "loss: tensor(0.4088) epoch: 53, step: 1\n",
      "loss: tensor(0.3601) epoch: 53, step: 2\n",
      "loss: tensor(0.3551) epoch: 53, step: 3\n",
      "loss: tensor(0.3595) epoch: 53, step: 4\n",
      "loss: tensor(0.3440) epoch: 53, step: 5\n",
      "loss: tensor(0.3323) epoch: 53, step: 6\n",
      "loss: tensor(0.3360) epoch: 53, step: 7\n",
      "Iteration :54\n",
      "loss: tensor(0.3070) epoch: 54, step: 0\n",
      "loss: tensor(0.3436) epoch: 54, step: 1\n",
      "loss: tensor(0.3473) epoch: 54, step: 2\n",
      "loss: tensor(0.3406) epoch: 54, step: 3\n",
      "loss: tensor(0.3370) epoch: 54, step: 4\n",
      "loss: tensor(0.3292) epoch: 54, step: 5\n",
      "loss: tensor(0.3386) epoch: 54, step: 6\n",
      "loss: tensor(0.3292) epoch: 54, step: 7\n",
      "Iteration :55\n",
      "loss: tensor(0.3183) epoch: 55, step: 0\n",
      "loss: tensor(0.3428) epoch: 55, step: 1\n",
      "loss: tensor(0.3142) epoch: 55, step: 2\n",
      "loss: tensor(0.3385) epoch: 55, step: 3\n",
      "loss: tensor(0.3388) epoch: 55, step: 4\n",
      "loss: tensor(0.3287) epoch: 55, step: 5\n",
      "loss: tensor(0.3216) epoch: 55, step: 6\n",
      "loss: tensor(0.3152) epoch: 55, step: 7\n",
      "Iteration :56\n",
      "loss: tensor(0.3394) epoch: 56, step: 0\n",
      "loss: tensor(0.3019) epoch: 56, step: 1\n",
      "loss: tensor(0.2884) epoch: 56, step: 2\n",
      "loss: tensor(0.2937) epoch: 56, step: 3\n",
      "loss: tensor(0.2950) epoch: 56, step: 4\n",
      "loss: tensor(0.2942) epoch: 56, step: 5\n",
      "loss: tensor(0.2936) epoch: 56, step: 6\n",
      "loss: tensor(0.2973) epoch: 56, step: 7\n",
      "Iteration :57\n",
      "loss: tensor(0.2675) epoch: 57, step: 0\n",
      "loss: tensor(0.2733) epoch: 57, step: 1\n",
      "loss: tensor(0.2689) epoch: 57, step: 2\n",
      "loss: tensor(0.2875) epoch: 57, step: 3\n",
      "loss: tensor(0.3079) epoch: 57, step: 4\n",
      "loss: tensor(0.3067) epoch: 57, step: 5\n",
      "loss: tensor(0.2987) epoch: 57, step: 6\n",
      "loss: tensor(0.2987) epoch: 57, step: 7\n",
      "Iteration :58\n",
      "loss: tensor(0.3045) epoch: 58, step: 0\n",
      "loss: tensor(0.2663) epoch: 58, step: 1\n",
      "loss: tensor(0.2538) epoch: 58, step: 2\n",
      "loss: tensor(0.2605) epoch: 58, step: 3\n",
      "loss: tensor(0.2654) epoch: 58, step: 4\n",
      "loss: tensor(0.2723) epoch: 58, step: 5\n",
      "loss: tensor(0.2746) epoch: 58, step: 6\n",
      "loss: tensor(0.2760) epoch: 58, step: 7\n",
      "Iteration :59\n",
      "loss: tensor(0.2417) epoch: 59, step: 0\n",
      "loss: tensor(0.2744) epoch: 59, step: 1\n",
      "loss: tensor(0.2875) epoch: 59, step: 2\n",
      "loss: tensor(0.2901) epoch: 59, step: 3\n",
      "loss: tensor(0.2873) epoch: 59, step: 4\n",
      "loss: tensor(0.2823) epoch: 59, step: 5\n",
      "loss: tensor(0.2741) epoch: 59, step: 6\n",
      "loss: tensor(0.2776) epoch: 59, step: 7\n",
      "Iteration :60\n",
      "loss: tensor(0.3007) epoch: 60, step: 0\n",
      "loss: tensor(0.3076) epoch: 60, step: 1\n",
      "loss: tensor(0.2861) epoch: 60, step: 2\n",
      "loss: tensor(0.2838) epoch: 60, step: 3\n",
      "loss: tensor(0.2797) epoch: 60, step: 4\n",
      "loss: tensor(0.2781) epoch: 60, step: 5\n",
      "loss: tensor(0.2772) epoch: 60, step: 6\n",
      "loss: tensor(0.2710) epoch: 60, step: 7\n",
      "Iteration :61\n",
      "loss: tensor(0.2916) epoch: 61, step: 0\n",
      "loss: tensor(0.2664) epoch: 61, step: 1\n",
      "loss: tensor(0.2563) epoch: 61, step: 2\n",
      "loss: tensor(0.2650) epoch: 61, step: 3\n",
      "loss: tensor(0.2807) epoch: 61, step: 4\n",
      "loss: tensor(0.2770) epoch: 61, step: 5\n",
      "loss: tensor(0.2801) epoch: 61, step: 6\n",
      "loss: tensor(0.2857) epoch: 61, step: 7\n",
      "Iteration :62\n",
      "loss: tensor(0.2394) epoch: 62, step: 0\n",
      "loss: tensor(0.2727) epoch: 62, step: 1\n",
      "loss: tensor(0.2589) epoch: 62, step: 2\n",
      "loss: tensor(0.2615) epoch: 62, step: 3\n",
      "loss: tensor(0.2599) epoch: 62, step: 4\n",
      "loss: tensor(0.2589) epoch: 62, step: 5\n",
      "loss: tensor(0.2577) epoch: 62, step: 6\n",
      "loss: tensor(0.2571) epoch: 62, step: 7\n",
      "Iteration :63\n",
      "loss: tensor(0.3049) epoch: 63, step: 0\n",
      "loss: tensor(0.2795) epoch: 63, step: 1\n",
      "loss: tensor(0.2675) epoch: 63, step: 2\n",
      "loss: tensor(0.2704) epoch: 63, step: 3\n",
      "loss: tensor(0.2617) epoch: 63, step: 4\n",
      "loss: tensor(0.2641) epoch: 63, step: 5\n",
      "loss: tensor(0.2718) epoch: 63, step: 6\n",
      "loss: tensor(0.2612) epoch: 63, step: 7\n",
      "Iteration :64\n",
      "loss: tensor(0.2408) epoch: 64, step: 0\n",
      "loss: tensor(0.2648) epoch: 64, step: 1\n",
      "loss: tensor(0.2510) epoch: 64, step: 2\n",
      "loss: tensor(0.2477) epoch: 64, step: 3\n",
      "loss: tensor(0.2585) epoch: 64, step: 4\n",
      "loss: tensor(0.2607) epoch: 64, step: 5\n",
      "loss: tensor(0.2520) epoch: 64, step: 6\n",
      "loss: tensor(0.2538) epoch: 64, step: 7\n",
      "Iteration :65\n",
      "loss: tensor(0.2184) epoch: 65, step: 0\n",
      "loss: tensor(0.2512) epoch: 65, step: 1\n",
      "loss: tensor(0.2399) epoch: 65, step: 2\n",
      "loss: tensor(0.2269) epoch: 65, step: 3\n",
      "loss: tensor(0.2348) epoch: 65, step: 4\n",
      "loss: tensor(0.2433) epoch: 65, step: 5\n",
      "loss: tensor(0.2482) epoch: 65, step: 6\n",
      "loss: tensor(0.2469) epoch: 65, step: 7\n",
      "Iteration :66\n",
      "loss: tensor(0.2265) epoch: 66, step: 0\n",
      "loss: tensor(0.2446) epoch: 66, step: 1\n",
      "loss: tensor(0.2338) epoch: 66, step: 2\n",
      "loss: tensor(0.2353) epoch: 66, step: 3\n",
      "loss: tensor(0.2598) epoch: 66, step: 4\n",
      "loss: tensor(0.2561) epoch: 66, step: 5\n",
      "loss: tensor(0.2588) epoch: 66, step: 6\n",
      "loss: tensor(0.2585) epoch: 66, step: 7\n",
      "Iteration :67\n",
      "loss: tensor(0.2244) epoch: 67, step: 0\n",
      "loss: tensor(0.2289) epoch: 67, step: 1\n",
      "loss: tensor(0.2213) epoch: 67, step: 2\n",
      "loss: tensor(0.2287) epoch: 67, step: 3\n",
      "loss: tensor(0.2394) epoch: 67, step: 4\n",
      "loss: tensor(0.2404) epoch: 67, step: 5\n",
      "loss: tensor(0.2411) epoch: 67, step: 6\n",
      "loss: tensor(0.2503) epoch: 67, step: 7\n",
      "Iteration :68\n",
      "loss: tensor(0.2587) epoch: 68, step: 0\n",
      "loss: tensor(0.2734) epoch: 68, step: 1\n",
      "loss: tensor(0.2517) epoch: 68, step: 2\n",
      "loss: tensor(0.2462) epoch: 68, step: 3\n",
      "loss: tensor(0.2492) epoch: 68, step: 4\n",
      "loss: tensor(0.2487) epoch: 68, step: 5\n",
      "loss: tensor(0.2449) epoch: 68, step: 6\n",
      "loss: tensor(0.2444) epoch: 68, step: 7\n",
      "Iteration :69\n",
      "loss: tensor(0.2068) epoch: 69, step: 0\n",
      "loss: tensor(0.2510) epoch: 69, step: 1\n",
      "loss: tensor(0.2373) epoch: 69, step: 2\n",
      "loss: tensor(0.2490) epoch: 69, step: 3\n",
      "loss: tensor(0.2461) epoch: 69, step: 4\n",
      "loss: tensor(0.2363) epoch: 69, step: 5\n",
      "loss: tensor(0.2392) epoch: 69, step: 6\n",
      "loss: tensor(0.2339) epoch: 69, step: 7\n",
      "Iteration :70\n",
      "loss: tensor(0.2279) epoch: 70, step: 0\n",
      "loss: tensor(0.2263) epoch: 70, step: 1\n",
      "loss: tensor(0.2249) epoch: 70, step: 2\n",
      "loss: tensor(0.2348) epoch: 70, step: 3\n",
      "loss: tensor(0.2340) epoch: 70, step: 4\n",
      "loss: tensor(0.2277) epoch: 70, step: 5\n",
      "loss: tensor(0.2197) epoch: 70, step: 6\n",
      "loss: tensor(0.2186) epoch: 70, step: 7\n",
      "Iteration :71\n",
      "loss: tensor(0.1969) epoch: 71, step: 0\n",
      "loss: tensor(0.2125) epoch: 71, step: 1\n",
      "loss: tensor(0.1943) epoch: 71, step: 2\n",
      "loss: tensor(0.2051) epoch: 71, step: 3\n",
      "loss: tensor(0.2108) epoch: 71, step: 4\n",
      "loss: tensor(0.2163) epoch: 71, step: 5\n",
      "loss: tensor(0.2268) epoch: 71, step: 6\n",
      "loss: tensor(0.2314) epoch: 71, step: 7\n",
      "Iteration :72\n",
      "loss: tensor(0.2053) epoch: 72, step: 0\n",
      "loss: tensor(0.2126) epoch: 72, step: 1\n",
      "loss: tensor(0.2325) epoch: 72, step: 2\n",
      "loss: tensor(0.2236) epoch: 72, step: 3\n",
      "loss: tensor(0.2184) epoch: 72, step: 4\n",
      "loss: tensor(0.2110) epoch: 72, step: 5\n",
      "loss: tensor(0.2163) epoch: 72, step: 6\n",
      "loss: tensor(0.2191) epoch: 72, step: 7\n",
      "Iteration :73\n",
      "loss: tensor(0.1772) epoch: 73, step: 0\n",
      "loss: tensor(0.1674) epoch: 73, step: 1\n",
      "loss: tensor(0.1646) epoch: 73, step: 2\n",
      "loss: tensor(0.1707) epoch: 73, step: 3\n",
      "loss: tensor(0.1930) epoch: 73, step: 4\n",
      "loss: tensor(0.1952) epoch: 73, step: 5\n",
      "loss: tensor(0.1941) epoch: 73, step: 6\n",
      "loss: tensor(0.1997) epoch: 73, step: 7\n",
      "Iteration :74\n",
      "loss: tensor(0.2088) epoch: 74, step: 0\n",
      "loss: tensor(0.2173) epoch: 74, step: 1\n",
      "loss: tensor(0.2284) epoch: 74, step: 2\n",
      "loss: tensor(0.2148) epoch: 74, step: 3\n",
      "loss: tensor(0.2099) epoch: 74, step: 4\n",
      "loss: tensor(0.2154) epoch: 74, step: 5\n",
      "loss: tensor(0.2082) epoch: 74, step: 6\n",
      "loss: tensor(0.2051) epoch: 74, step: 7\n",
      "Iteration :75\n",
      "loss: tensor(0.2239) epoch: 75, step: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0.2033) epoch: 75, step: 1\n",
      "loss: tensor(0.2035) epoch: 75, step: 2\n",
      "loss: tensor(0.2088) epoch: 75, step: 3\n",
      "loss: tensor(0.2047) epoch: 75, step: 4\n",
      "loss: tensor(0.2055) epoch: 75, step: 5\n",
      "loss: tensor(0.2034) epoch: 75, step: 6\n",
      "loss: tensor(0.2003) epoch: 75, step: 7\n",
      "Iteration :76\n",
      "loss: tensor(0.1845) epoch: 76, step: 0\n",
      "loss: tensor(0.1750) epoch: 76, step: 1\n",
      "loss: tensor(0.1865) epoch: 76, step: 2\n",
      "loss: tensor(0.1977) epoch: 76, step: 3\n",
      "loss: tensor(0.2108) epoch: 76, step: 4\n",
      "loss: tensor(0.2045) epoch: 76, step: 5\n",
      "loss: tensor(0.2041) epoch: 76, step: 6\n",
      "loss: tensor(0.2016) epoch: 76, step: 7\n",
      "Iteration :77\n",
      "loss: tensor(0.2158) epoch: 77, step: 0\n",
      "loss: tensor(0.2083) epoch: 77, step: 1\n",
      "loss: tensor(0.2066) epoch: 77, step: 2\n",
      "loss: tensor(0.2024) epoch: 77, step: 3\n",
      "loss: tensor(0.2079) epoch: 77, step: 4\n",
      "loss: tensor(0.2129) epoch: 77, step: 5\n",
      "loss: tensor(0.2056) epoch: 77, step: 6\n",
      "loss: tensor(0.2004) epoch: 77, step: 7\n",
      "Iteration :78\n",
      "loss: tensor(0.1919) epoch: 78, step: 0\n",
      "loss: tensor(0.1920) epoch: 78, step: 1\n",
      "loss: tensor(0.1845) epoch: 78, step: 2\n",
      "loss: tensor(0.1773) epoch: 78, step: 3\n",
      "loss: tensor(0.1840) epoch: 78, step: 4\n",
      "loss: tensor(0.1805) epoch: 78, step: 5\n",
      "loss: tensor(0.1811) epoch: 78, step: 6\n",
      "loss: tensor(0.1835) epoch: 78, step: 7\n",
      "Iteration :79\n",
      "loss: tensor(0.1818) epoch: 79, step: 0\n",
      "loss: tensor(0.1743) epoch: 79, step: 1\n",
      "loss: tensor(0.1686) epoch: 79, step: 2\n",
      "loss: tensor(0.1752) epoch: 79, step: 3\n",
      "loss: tensor(0.1861) epoch: 79, step: 4\n",
      "loss: tensor(0.2013) epoch: 79, step: 5\n",
      "loss: tensor(0.1918) epoch: 79, step: 6\n",
      "loss: tensor(0.1917) epoch: 79, step: 7\n",
      "Iteration :80\n",
      "loss: tensor(0.1876) epoch: 80, step: 0\n",
      "loss: tensor(0.1907) epoch: 80, step: 1\n",
      "loss: tensor(0.2029) epoch: 80, step: 2\n",
      "loss: tensor(0.2068) epoch: 80, step: 3\n",
      "loss: tensor(0.1994) epoch: 80, step: 4\n",
      "loss: tensor(0.1973) epoch: 80, step: 5\n",
      "loss: tensor(0.1957) epoch: 80, step: 6\n",
      "loss: tensor(0.1947) epoch: 80, step: 7\n",
      "Iteration :81\n",
      "loss: tensor(0.1809) epoch: 81, step: 0\n",
      "loss: tensor(0.1741) epoch: 81, step: 1\n",
      "loss: tensor(0.1871) epoch: 81, step: 2\n",
      "loss: tensor(0.1871) epoch: 81, step: 3\n",
      "loss: tensor(0.1965) epoch: 81, step: 4\n",
      "loss: tensor(0.1955) epoch: 81, step: 5\n",
      "loss: tensor(0.1945) epoch: 81, step: 6\n",
      "loss: tensor(0.1902) epoch: 81, step: 7\n",
      "Iteration :82\n",
      "loss: tensor(0.1942) epoch: 82, step: 0\n",
      "loss: tensor(0.1806) epoch: 82, step: 1\n",
      "loss: tensor(0.1665) epoch: 82, step: 2\n",
      "loss: tensor(0.2075) epoch: 82, step: 3\n",
      "loss: tensor(0.2000) epoch: 82, step: 4\n",
      "loss: tensor(0.1951) epoch: 82, step: 5\n",
      "loss: tensor(0.1988) epoch: 82, step: 6\n",
      "loss: tensor(0.2042) epoch: 82, step: 7\n",
      "Iteration :83\n",
      "loss: tensor(0.1828) epoch: 83, step: 0\n",
      "loss: tensor(0.1644) epoch: 83, step: 1\n",
      "loss: tensor(0.1742) epoch: 83, step: 2\n",
      "loss: tensor(0.1768) epoch: 83, step: 3\n",
      "loss: tensor(0.1735) epoch: 83, step: 4\n",
      "loss: tensor(0.1738) epoch: 83, step: 5\n",
      "loss: tensor(0.1837) epoch: 83, step: 6\n",
      "loss: tensor(0.1846) epoch: 83, step: 7\n",
      "Iteration :84\n",
      "loss: tensor(0.1307) epoch: 84, step: 0\n",
      "loss: tensor(0.1567) epoch: 84, step: 1\n",
      "loss: tensor(0.1643) epoch: 84, step: 2\n",
      "loss: tensor(0.1626) epoch: 84, step: 3\n",
      "loss: tensor(0.2021) epoch: 84, step: 4\n",
      "loss: tensor(0.2096) epoch: 84, step: 5\n",
      "loss: tensor(0.2071) epoch: 84, step: 6\n",
      "loss: tensor(0.2089) epoch: 84, step: 7\n",
      "Iteration :85\n",
      "loss: tensor(0.2194) epoch: 85, step: 0\n",
      "loss: tensor(0.2245) epoch: 85, step: 1\n",
      "loss: tensor(0.2123) epoch: 85, step: 2\n",
      "loss: tensor(0.2061) epoch: 85, step: 3\n",
      "loss: tensor(0.2061) epoch: 85, step: 4\n",
      "loss: tensor(0.2012) epoch: 85, step: 5\n",
      "loss: tensor(0.1975) epoch: 85, step: 6\n",
      "loss: tensor(0.1968) epoch: 85, step: 7\n",
      "Iteration :86\n",
      "loss: tensor(0.2510) epoch: 86, step: 0\n",
      "loss: tensor(0.2173) epoch: 86, step: 1\n",
      "loss: tensor(0.2053) epoch: 86, step: 2\n",
      "loss: tensor(0.1953) epoch: 86, step: 3\n",
      "loss: tensor(0.1935) epoch: 86, step: 4\n",
      "loss: tensor(0.1862) epoch: 86, step: 5\n",
      "loss: tensor(0.1840) epoch: 86, step: 6\n",
      "loss: tensor(0.1859) epoch: 86, step: 7\n",
      "Iteration :87\n",
      "loss: tensor(0.2079) epoch: 87, step: 0\n",
      "loss: tensor(0.1924) epoch: 87, step: 1\n",
      "loss: tensor(0.1695) epoch: 87, step: 2\n",
      "loss: tensor(0.1679) epoch: 87, step: 3\n",
      "loss: tensor(0.1736) epoch: 87, step: 4\n",
      "loss: tensor(0.1799) epoch: 87, step: 5\n",
      "loss: tensor(0.1840) epoch: 87, step: 6\n",
      "loss: tensor(0.1835) epoch: 87, step: 7\n",
      "Iteration :88\n",
      "loss: tensor(0.1785) epoch: 88, step: 0\n",
      "loss: tensor(0.1813) epoch: 88, step: 1\n",
      "loss: tensor(0.1756) epoch: 88, step: 2\n",
      "loss: tensor(0.1850) epoch: 88, step: 3\n",
      "loss: tensor(0.1776) epoch: 88, step: 4\n",
      "loss: tensor(0.1825) epoch: 88, step: 5\n",
      "loss: tensor(0.1751) epoch: 88, step: 6\n",
      "loss: tensor(0.1754) epoch: 88, step: 7\n",
      "Iteration :89\n",
      "loss: tensor(0.1612) epoch: 89, step: 0\n",
      "loss: tensor(0.1879) epoch: 89, step: 1\n",
      "loss: tensor(0.1803) epoch: 89, step: 2\n",
      "loss: tensor(0.1739) epoch: 89, step: 3\n",
      "loss: tensor(0.1658) epoch: 89, step: 4\n",
      "loss: tensor(0.1770) epoch: 89, step: 5\n",
      "loss: tensor(0.1755) epoch: 89, step: 6\n",
      "loss: tensor(0.1729) epoch: 89, step: 7\n",
      "Iteration :90\n",
      "loss: tensor(0.2002) epoch: 90, step: 0\n",
      "loss: tensor(0.2081) epoch: 90, step: 1\n",
      "loss: tensor(0.1880) epoch: 90, step: 2\n",
      "loss: tensor(0.1760) epoch: 90, step: 3\n",
      "loss: tensor(0.1705) epoch: 90, step: 4\n",
      "loss: tensor(0.1739) epoch: 90, step: 5\n",
      "loss: tensor(0.1754) epoch: 90, step: 6\n",
      "loss: tensor(0.1697) epoch: 90, step: 7\n",
      "Iteration :91\n",
      "loss: tensor(0.1557) epoch: 91, step: 0\n",
      "loss: tensor(0.1586) epoch: 91, step: 1\n",
      "loss: tensor(0.1727) epoch: 91, step: 2\n",
      "loss: tensor(0.1680) epoch: 91, step: 3\n",
      "loss: tensor(0.1646) epoch: 91, step: 4\n",
      "loss: tensor(0.1668) epoch: 91, step: 5\n",
      "loss: tensor(0.1674) epoch: 91, step: 6\n",
      "loss: tensor(0.1611) epoch: 91, step: 7\n",
      "Iteration :92\n",
      "loss: tensor(0.2233) epoch: 92, step: 0\n",
      "loss: tensor(0.1661) epoch: 92, step: 1\n",
      "loss: tensor(0.1715) epoch: 92, step: 2\n",
      "loss: tensor(0.1740) epoch: 92, step: 3\n",
      "loss: tensor(0.1689) epoch: 92, step: 4\n",
      "loss: tensor(0.1696) epoch: 92, step: 5\n",
      "loss: tensor(0.1692) epoch: 92, step: 6\n",
      "loss: tensor(0.1708) epoch: 92, step: 7\n",
      "Iteration :93\n",
      "loss: tensor(0.2295) epoch: 93, step: 0\n",
      "loss: tensor(0.1929) epoch: 93, step: 1\n",
      "loss: tensor(0.1821) epoch: 93, step: 2\n",
      "loss: tensor(0.1703) epoch: 93, step: 3\n",
      "loss: tensor(0.1661) epoch: 93, step: 4\n",
      "loss: tensor(0.1728) epoch: 93, step: 5\n",
      "loss: tensor(0.1707) epoch: 93, step: 6\n",
      "loss: tensor(0.1670) epoch: 93, step: 7\n",
      "Iteration :94\n",
      "loss: tensor(0.1756) epoch: 94, step: 0\n",
      "loss: tensor(0.1751) epoch: 94, step: 1\n",
      "loss: tensor(0.1715) epoch: 94, step: 2\n",
      "loss: tensor(0.1716) epoch: 94, step: 3\n",
      "loss: tensor(0.1668) epoch: 94, step: 4\n",
      "loss: tensor(0.1618) epoch: 94, step: 5\n",
      "loss: tensor(0.1642) epoch: 94, step: 6\n",
      "loss: tensor(0.1607) epoch: 94, step: 7\n",
      "Iteration :95\n",
      "loss: tensor(0.2183) epoch: 95, step: 0\n",
      "loss: tensor(0.2033) epoch: 95, step: 1\n",
      "loss: tensor(0.1976) epoch: 95, step: 2\n",
      "loss: tensor(0.1806) epoch: 95, step: 3\n",
      "loss: tensor(0.1785) epoch: 95, step: 4\n",
      "loss: tensor(0.1723) epoch: 95, step: 5\n",
      "loss: tensor(0.1660) epoch: 95, step: 6\n",
      "loss: tensor(0.1634) epoch: 95, step: 7\n",
      "Iteration :96\n",
      "loss: tensor(0.1589) epoch: 96, step: 0\n",
      "loss: tensor(0.1459) epoch: 96, step: 1\n",
      "loss: tensor(0.1726) epoch: 96, step: 2\n",
      "loss: tensor(0.1677) epoch: 96, step: 3\n",
      "loss: tensor(0.1628) epoch: 96, step: 4\n",
      "loss: tensor(0.1612) epoch: 96, step: 5\n",
      "loss: tensor(0.1633) epoch: 96, step: 6\n",
      "loss: tensor(0.1577) epoch: 96, step: 7\n",
      "Iteration :97\n",
      "loss: tensor(0.1544) epoch: 97, step: 0\n",
      "loss: tensor(0.1277) epoch: 97, step: 1\n",
      "loss: tensor(0.1382) epoch: 97, step: 2\n",
      "loss: tensor(0.1365) epoch: 97, step: 3\n",
      "loss: tensor(0.1420) epoch: 97, step: 4\n",
      "loss: tensor(0.1467) epoch: 97, step: 5\n",
      "loss: tensor(0.1469) epoch: 97, step: 6\n",
      "loss: tensor(0.1490) epoch: 97, step: 7\n",
      "Iteration :98\n",
      "loss: tensor(0.1700) epoch: 98, step: 0\n",
      "loss: tensor(0.1478) epoch: 98, step: 1\n",
      "loss: tensor(0.1448) epoch: 98, step: 2\n",
      "loss: tensor(0.1484) epoch: 98, step: 3\n",
      "loss: tensor(0.1416) epoch: 98, step: 4\n",
      "loss: tensor(0.1465) epoch: 98, step: 5\n",
      "loss: tensor(0.1449) epoch: 98, step: 6\n",
      "loss: tensor(0.1467) epoch: 98, step: 7\n",
      "Iteration :99\n",
      "loss: tensor(0.1555) epoch: 99, step: 0\n",
      "loss: tensor(0.1682) epoch: 99, step: 1\n",
      "loss: tensor(0.1403) epoch: 99, step: 2\n",
      "loss: tensor(0.1398) epoch: 99, step: 3\n",
      "loss: tensor(0.1459) epoch: 99, step: 4\n",
      "loss: tensor(0.1474) epoch: 99, step: 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0.1516) epoch: 99, step: 6\n",
      "loss: tensor(0.1514) epoch: 99, step: 7\n",
      "Iteration :100\n",
      "loss: tensor(0.1414) epoch: 100, step: 0\n",
      "loss: tensor(0.1488) epoch: 100, step: 1\n",
      "loss: tensor(0.1435) epoch: 100, step: 2\n",
      "loss: tensor(0.1463) epoch: 100, step: 3\n",
      "loss: tensor(0.1423) epoch: 100, step: 4\n",
      "loss: tensor(0.1410) epoch: 100, step: 5\n",
      "loss: tensor(0.1371) epoch: 100, step: 6\n",
      "loss: tensor(0.1401) epoch: 100, step: 7\n",
      "Iteration :101\n",
      "loss: tensor(0.1769) epoch: 101, step: 0\n",
      "loss: tensor(0.1642) epoch: 101, step: 1\n",
      "loss: tensor(0.1526) epoch: 101, step: 2\n",
      "loss: tensor(0.1522) epoch: 101, step: 3\n",
      "loss: tensor(0.1560) epoch: 101, step: 4\n",
      "loss: tensor(0.1473) epoch: 101, step: 5\n",
      "loss: tensor(0.1522) epoch: 101, step: 6\n",
      "loss: tensor(0.1666) epoch: 101, step: 7\n",
      "Iteration :102\n",
      "loss: tensor(0.2708) epoch: 102, step: 0\n",
      "loss: tensor(0.2386) epoch: 102, step: 1\n",
      "loss: tensor(0.2017) epoch: 102, step: 2\n",
      "loss: tensor(0.2086) epoch: 102, step: 3\n",
      "loss: tensor(0.2060) epoch: 102, step: 4\n",
      "loss: tensor(0.1932) epoch: 102, step: 5\n",
      "loss: tensor(0.1901) epoch: 102, step: 6\n",
      "loss: tensor(0.1869) epoch: 102, step: 7\n",
      "Iteration :103\n",
      "loss: tensor(0.1620) epoch: 103, step: 0\n",
      "loss: tensor(0.1595) epoch: 103, step: 1\n",
      "loss: tensor(0.1455) epoch: 103, step: 2\n",
      "loss: tensor(0.1422) epoch: 103, step: 3\n",
      "loss: tensor(0.1479) epoch: 103, step: 4\n",
      "loss: tensor(0.1496) epoch: 103, step: 5\n",
      "loss: tensor(0.1492) epoch: 103, step: 6\n",
      "loss: tensor(0.1530) epoch: 103, step: 7\n",
      "Iteration :104\n",
      "loss: tensor(0.1943) epoch: 104, step: 0\n",
      "loss: tensor(0.1679) epoch: 104, step: 1\n",
      "loss: tensor(0.1715) epoch: 104, step: 2\n",
      "loss: tensor(0.1622) epoch: 104, step: 3\n",
      "loss: tensor(0.1727) epoch: 104, step: 4\n",
      "loss: tensor(0.1733) epoch: 104, step: 5\n",
      "loss: tensor(0.1676) epoch: 104, step: 6\n",
      "loss: tensor(0.1614) epoch: 104, step: 7\n",
      "Iteration :105\n",
      "loss: tensor(0.1238) epoch: 105, step: 0\n",
      "loss: tensor(0.1685) epoch: 105, step: 1\n",
      "loss: tensor(0.1796) epoch: 105, step: 2\n",
      "loss: tensor(0.1691) epoch: 105, step: 3\n",
      "loss: tensor(0.1584) epoch: 105, step: 4\n",
      "loss: tensor(0.1593) epoch: 105, step: 5\n",
      "loss: tensor(0.1560) epoch: 105, step: 6\n",
      "loss: tensor(0.1599) epoch: 105, step: 7\n",
      "Iteration :106\n",
      "loss: tensor(0.1477) epoch: 106, step: 0\n",
      "loss: tensor(0.1445) epoch: 106, step: 1\n",
      "loss: tensor(0.1439) epoch: 106, step: 2\n",
      "loss: tensor(0.1621) epoch: 106, step: 3\n",
      "loss: tensor(0.1470) epoch: 106, step: 4\n",
      "loss: tensor(0.1521) epoch: 106, step: 5\n",
      "loss: tensor(0.1519) epoch: 106, step: 6\n",
      "loss: tensor(0.1492) epoch: 106, step: 7\n",
      "Iteration :107\n",
      "loss: tensor(0.1626) epoch: 107, step: 0\n",
      "loss: tensor(0.1387) epoch: 107, step: 1\n",
      "loss: tensor(0.1427) epoch: 107, step: 2\n",
      "loss: tensor(0.1340) epoch: 107, step: 3\n",
      "loss: tensor(0.1361) epoch: 107, step: 4\n",
      "loss: tensor(0.1339) epoch: 107, step: 5\n",
      "loss: tensor(0.1350) epoch: 107, step: 6\n",
      "loss: tensor(0.1375) epoch: 107, step: 7\n",
      "Iteration :108\n",
      "loss: tensor(0.1922) epoch: 108, step: 0\n",
      "loss: tensor(0.1525) epoch: 108, step: 1\n",
      "loss: tensor(0.1493) epoch: 108, step: 2\n",
      "loss: tensor(0.1524) epoch: 108, step: 3\n",
      "loss: tensor(0.1456) epoch: 108, step: 4\n",
      "loss: tensor(0.1392) epoch: 108, step: 5\n",
      "loss: tensor(0.1404) epoch: 108, step: 6\n",
      "loss: tensor(0.1358) epoch: 108, step: 7\n",
      "Iteration :109\n",
      "loss: tensor(0.1103) epoch: 109, step: 0\n",
      "loss: tensor(0.1223) epoch: 109, step: 1\n",
      "loss: tensor(0.1279) epoch: 109, step: 2\n",
      "loss: tensor(0.1279) epoch: 109, step: 3\n",
      "loss: tensor(0.1347) epoch: 109, step: 4\n",
      "loss: tensor(0.1381) epoch: 109, step: 5\n",
      "loss: tensor(0.1354) epoch: 109, step: 6\n",
      "loss: tensor(0.1401) epoch: 109, step: 7\n",
      "Iteration :110\n",
      "loss: tensor(0.1398) epoch: 110, step: 0\n",
      "loss: tensor(0.1171) epoch: 110, step: 1\n",
      "loss: tensor(0.1250) epoch: 110, step: 2\n",
      "loss: tensor(0.1235) epoch: 110, step: 3\n",
      "loss: tensor(0.1313) epoch: 110, step: 4\n",
      "loss: tensor(0.1341) epoch: 110, step: 5\n",
      "loss: tensor(0.1334) epoch: 110, step: 6\n",
      "loss: tensor(0.1334) epoch: 110, step: 7\n",
      "Iteration :111\n",
      "loss: tensor(0.1239) epoch: 111, step: 0\n",
      "loss: tensor(0.1341) epoch: 111, step: 1\n",
      "loss: tensor(0.1390) epoch: 111, step: 2\n",
      "loss: tensor(0.1375) epoch: 111, step: 3\n",
      "loss: tensor(0.1342) epoch: 111, step: 4\n",
      "loss: tensor(0.1301) epoch: 111, step: 5\n",
      "loss: tensor(0.1239) epoch: 111, step: 6\n",
      "loss: tensor(0.1205) epoch: 111, step: 7\n",
      "Iteration :112\n",
      "loss: tensor(0.1189) epoch: 112, step: 0\n",
      "loss: tensor(0.1162) epoch: 112, step: 1\n",
      "loss: tensor(0.1117) epoch: 112, step: 2\n",
      "loss: tensor(0.1174) epoch: 112, step: 3\n",
      "loss: tensor(0.1206) epoch: 112, step: 4\n",
      "loss: tensor(0.1227) epoch: 112, step: 5\n",
      "loss: tensor(0.1252) epoch: 112, step: 6\n",
      "loss: tensor(0.1265) epoch: 112, step: 7\n",
      "Iteration :113\n",
      "loss: tensor(0.1892) epoch: 113, step: 0\n",
      "loss: tensor(0.1651) epoch: 113, step: 1\n",
      "loss: tensor(0.1390) epoch: 113, step: 2\n",
      "loss: tensor(0.1345) epoch: 113, step: 3\n",
      "loss: tensor(0.1344) epoch: 113, step: 4\n",
      "loss: tensor(0.1413) epoch: 113, step: 5\n",
      "loss: tensor(0.1408) epoch: 113, step: 6\n",
      "loss: tensor(0.1452) epoch: 113, step: 7\n",
      "Iteration :114\n",
      "loss: tensor(0.1127) epoch: 114, step: 0\n",
      "loss: tensor(0.1082) epoch: 114, step: 1\n",
      "loss: tensor(0.1165) epoch: 114, step: 2\n",
      "loss: tensor(0.1201) epoch: 114, step: 3\n",
      "loss: tensor(0.1206) epoch: 114, step: 4\n",
      "loss: tensor(0.1198) epoch: 114, step: 5\n",
      "loss: tensor(0.1261) epoch: 114, step: 6\n",
      "loss: tensor(0.1291) epoch: 114, step: 7\n",
      "Iteration :115\n",
      "loss: tensor(0.1184) epoch: 115, step: 0\n",
      "loss: tensor(0.1239) epoch: 115, step: 1\n",
      "loss: tensor(0.1231) epoch: 115, step: 2\n",
      "loss: tensor(0.1320) epoch: 115, step: 3\n",
      "loss: tensor(0.1295) epoch: 115, step: 4\n",
      "loss: tensor(0.1328) epoch: 115, step: 5\n",
      "loss: tensor(0.1290) epoch: 115, step: 6\n",
      "loss: tensor(0.1287) epoch: 115, step: 7\n",
      "Iteration :116\n",
      "loss: tensor(0.1267) epoch: 116, step: 0\n",
      "loss: tensor(0.1232) epoch: 116, step: 1\n",
      "loss: tensor(0.1178) epoch: 116, step: 2\n",
      "loss: tensor(0.1210) epoch: 116, step: 3\n",
      "loss: tensor(0.1169) epoch: 116, step: 4\n",
      "loss: tensor(0.1200) epoch: 116, step: 5\n",
      "loss: tensor(0.1238) epoch: 116, step: 6\n",
      "loss: tensor(0.1287) epoch: 116, step: 7\n",
      "Iteration :117\n",
      "loss: tensor(0.1786) epoch: 117, step: 0\n",
      "loss: tensor(0.1505) epoch: 117, step: 1\n",
      "loss: tensor(0.1376) epoch: 117, step: 2\n",
      "loss: tensor(0.1342) epoch: 117, step: 3\n",
      "loss: tensor(0.1323) epoch: 117, step: 4\n",
      "loss: tensor(0.1370) epoch: 117, step: 5\n",
      "loss: tensor(0.1331) epoch: 117, step: 6\n",
      "loss: tensor(0.1287) epoch: 117, step: 7\n",
      "Iteration :118\n",
      "loss: tensor(0.1259) epoch: 118, step: 0\n",
      "loss: tensor(0.1117) epoch: 118, step: 1\n",
      "loss: tensor(0.1129) epoch: 118, step: 2\n",
      "loss: tensor(0.1160) epoch: 118, step: 3\n",
      "loss: tensor(0.1172) epoch: 118, step: 4\n",
      "loss: tensor(0.1190) epoch: 118, step: 5\n",
      "loss: tensor(0.1145) epoch: 118, step: 6\n",
      "loss: tensor(0.1180) epoch: 118, step: 7\n",
      "Iteration :119\n",
      "loss: tensor(0.1114) epoch: 119, step: 0\n",
      "loss: tensor(0.1249) epoch: 119, step: 1\n",
      "loss: tensor(0.1205) epoch: 119, step: 2\n",
      "loss: tensor(0.1283) epoch: 119, step: 3\n",
      "loss: tensor(0.1211) epoch: 119, step: 4\n",
      "loss: tensor(0.1210) epoch: 119, step: 5\n",
      "loss: tensor(0.1157) epoch: 119, step: 6\n",
      "loss: tensor(0.1159) epoch: 119, step: 7\n",
      "Iteration :120\n",
      "loss: tensor(0.1277) epoch: 120, step: 0\n",
      "loss: tensor(0.1116) epoch: 120, step: 1\n",
      "loss: tensor(0.1069) epoch: 120, step: 2\n",
      "loss: tensor(0.1075) epoch: 120, step: 3\n",
      "loss: tensor(0.1104) epoch: 120, step: 4\n",
      "loss: tensor(0.1100) epoch: 120, step: 5\n",
      "loss: tensor(0.1094) epoch: 120, step: 6\n",
      "loss: tensor(0.1120) epoch: 120, step: 7\n",
      "Iteration :121\n",
      "loss: tensor(1.00000e-02 *\n",
      "       9.5087) epoch: 121, step: 0\n",
      "loss: tensor(1.00000e-02 *\n",
      "       9.4184) epoch: 121, step: 1\n",
      "loss: tensor(0.1035) epoch: 121, step: 2\n",
      "loss: tensor(0.1038) epoch: 121, step: 3\n",
      "loss: tensor(0.1075) epoch: 121, step: 4\n",
      "loss: tensor(0.2354) epoch: 121, step: 5\n",
      "loss: tensor(0.2615) epoch: 121, step: 6\n",
      "loss: tensor(0.2627) epoch: 121, step: 7\n",
      "Iteration :122\n",
      "loss: tensor(0.1573) epoch: 122, step: 0\n",
      "loss: tensor(0.1637) epoch: 122, step: 1\n",
      "loss: tensor(0.1564) epoch: 122, step: 2\n",
      "loss: tensor(0.1572) epoch: 122, step: 3\n",
      "loss: tensor(0.1665) epoch: 122, step: 4\n",
      "loss: tensor(0.1641) epoch: 122, step: 5\n",
      "loss: tensor(0.1601) epoch: 122, step: 6\n",
      "loss: tensor(0.1634) epoch: 122, step: 7\n",
      "Iteration :123\n",
      "loss: tensor(0.2020) epoch: 123, step: 0\n",
      "loss: tensor(0.1995) epoch: 123, step: 1\n",
      "loss: tensor(0.1990) epoch: 123, step: 2\n",
      "loss: tensor(0.2016) epoch: 123, step: 3\n",
      "loss: tensor(0.1858) epoch: 123, step: 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0.1843) epoch: 123, step: 5\n",
      "loss: tensor(0.1758) epoch: 123, step: 6\n",
      "loss: tensor(0.1672) epoch: 123, step: 7\n",
      "Iteration :124\n",
      "loss: tensor(0.1918) epoch: 124, step: 0\n",
      "loss: tensor(0.2089) epoch: 124, step: 1\n",
      "loss: tensor(0.1878) epoch: 124, step: 2\n",
      "loss: tensor(0.1892) epoch: 124, step: 3\n",
      "loss: tensor(0.1896) epoch: 124, step: 4\n",
      "loss: tensor(0.1847) epoch: 124, step: 5\n",
      "loss: tensor(0.1768) epoch: 124, step: 6\n",
      "loss: tensor(0.1694) epoch: 124, step: 7\n",
      "Iteration :125\n",
      "loss: tensor(1.00000e-02 *\n",
      "       9.4820) epoch: 125, step: 0\n",
      "loss: tensor(0.1204) epoch: 125, step: 1\n",
      "loss: tensor(0.1120) epoch: 125, step: 2\n",
      "loss: tensor(0.1207) epoch: 125, step: 3\n",
      "loss: tensor(0.1320) epoch: 125, step: 4\n",
      "loss: tensor(0.1366) epoch: 125, step: 5\n",
      "loss: tensor(0.1378) epoch: 125, step: 6\n",
      "loss: tensor(0.1365) epoch: 125, step: 7\n",
      "Iteration :126\n",
      "loss: tensor(0.1143) epoch: 126, step: 0\n",
      "loss: tensor(0.1382) epoch: 126, step: 1\n",
      "loss: tensor(0.1258) epoch: 126, step: 2\n",
      "loss: tensor(0.1174) epoch: 126, step: 3\n",
      "loss: tensor(0.1215) epoch: 126, step: 4\n",
      "loss: tensor(0.1229) epoch: 126, step: 5\n",
      "loss: tensor(0.1274) epoch: 126, step: 6\n",
      "loss: tensor(0.1252) epoch: 126, step: 7\n",
      "Iteration :127\n",
      "loss: tensor(0.2269) epoch: 127, step: 0\n",
      "loss: tensor(0.1621) epoch: 127, step: 1\n",
      "loss: tensor(0.1542) epoch: 127, step: 2\n",
      "loss: tensor(0.1441) epoch: 127, step: 3\n",
      "loss: tensor(0.1366) epoch: 127, step: 4\n",
      "loss: tensor(0.1369) epoch: 127, step: 5\n",
      "loss: tensor(0.1328) epoch: 127, step: 6\n",
      "loss: tensor(0.1399) epoch: 127, step: 7\n",
      "Iteration :128\n",
      "loss: tensor(0.1573) epoch: 128, step: 0\n",
      "loss: tensor(0.1405) epoch: 128, step: 1\n",
      "loss: tensor(0.1254) epoch: 128, step: 2\n",
      "loss: tensor(0.1340) epoch: 128, step: 3\n",
      "loss: tensor(0.1305) epoch: 128, step: 4\n",
      "loss: tensor(0.1344) epoch: 128, step: 5\n",
      "loss: tensor(0.1334) epoch: 128, step: 6\n",
      "loss: tensor(0.1298) epoch: 128, step: 7\n",
      "Iteration :129\n",
      "loss: tensor(0.1684) epoch: 129, step: 0\n",
      "loss: tensor(0.1514) epoch: 129, step: 1\n",
      "loss: tensor(0.1427) epoch: 129, step: 2\n",
      "loss: tensor(0.1335) epoch: 129, step: 3\n",
      "loss: tensor(0.1290) epoch: 129, step: 4\n",
      "loss: tensor(0.1280) epoch: 129, step: 5\n",
      "loss: tensor(0.1259) epoch: 129, step: 6\n",
      "loss: tensor(0.1266) epoch: 129, step: 7\n",
      "Iteration :130\n",
      "loss: tensor(0.1315) epoch: 130, step: 0\n",
      "loss: tensor(0.1321) epoch: 130, step: 1\n",
      "loss: tensor(0.1270) epoch: 130, step: 2\n",
      "loss: tensor(0.1209) epoch: 130, step: 3\n",
      "loss: tensor(0.1237) epoch: 130, step: 4\n",
      "loss: tensor(0.1226) epoch: 130, step: 5\n",
      "loss: tensor(0.1263) epoch: 130, step: 6\n",
      "loss: tensor(0.1243) epoch: 130, step: 7\n",
      "Iteration :131\n",
      "loss: tensor(0.1281) epoch: 131, step: 0\n",
      "loss: tensor(0.1139) epoch: 131, step: 1\n",
      "loss: tensor(0.1186) epoch: 131, step: 2\n",
      "loss: tensor(0.1135) epoch: 131, step: 3\n",
      "loss: tensor(0.1161) epoch: 131, step: 4\n",
      "loss: tensor(0.1215) epoch: 131, step: 5\n",
      "loss: tensor(0.1184) epoch: 131, step: 6\n",
      "loss: tensor(0.1163) epoch: 131, step: 7\n",
      "Iteration :132\n",
      "loss: tensor(1.00000e-02 *\n",
      "       7.5615) epoch: 132, step: 0\n",
      "loss: tensor(0.1045) epoch: 132, step: 1\n",
      "loss: tensor(0.1148) epoch: 132, step: 2\n",
      "loss: tensor(0.1150) epoch: 132, step: 3\n",
      "loss: tensor(0.1131) epoch: 132, step: 4\n",
      "loss: tensor(0.1169) epoch: 132, step: 5\n",
      "loss: tensor(0.1175) epoch: 132, step: 6\n",
      "loss: tensor(0.1186) epoch: 132, step: 7\n",
      "Iteration :133\n",
      "loss: tensor(0.1325) epoch: 133, step: 0\n",
      "loss: tensor(0.1373) epoch: 133, step: 1\n",
      "loss: tensor(0.1215) epoch: 133, step: 2\n",
      "loss: tensor(0.1195) epoch: 133, step: 3\n",
      "loss: tensor(0.1141) epoch: 133, step: 4\n",
      "loss: tensor(0.1103) epoch: 133, step: 5\n",
      "loss: tensor(0.1176) epoch: 133, step: 6\n",
      "loss: tensor(0.1190) epoch: 133, step: 7\n",
      "Iteration :134\n",
      "loss: tensor(1.00000e-02 *\n",
      "       8.6740) epoch: 134, step: 0\n",
      "loss: tensor(0.1158) epoch: 134, step: 1\n",
      "loss: tensor(0.1079) epoch: 134, step: 2\n",
      "loss: tensor(0.1100) epoch: 134, step: 3\n",
      "loss: tensor(0.1159) epoch: 134, step: 4\n",
      "loss: tensor(0.1231) epoch: 134, step: 5\n",
      "loss: tensor(0.1209) epoch: 134, step: 6\n",
      "loss: tensor(0.1208) epoch: 134, step: 7\n",
      "Iteration :135\n",
      "loss: tensor(1.00000e-02 *\n",
      "       9.6425) epoch: 135, step: 0\n",
      "loss: tensor(0.1045) epoch: 135, step: 1\n",
      "loss: tensor(0.1081) epoch: 135, step: 2\n",
      "loss: tensor(0.1154) epoch: 135, step: 3\n",
      "loss: tensor(0.1154) epoch: 135, step: 4\n",
      "loss: tensor(0.1108) epoch: 135, step: 5\n",
      "loss: tensor(0.1140) epoch: 135, step: 6\n",
      "loss: tensor(0.1109) epoch: 135, step: 7\n",
      "Iteration :136\n",
      "loss: tensor(0.1301) epoch: 136, step: 0\n",
      "loss: tensor(0.1948) epoch: 136, step: 1\n",
      "loss: tensor(0.1876) epoch: 136, step: 2\n",
      "loss: tensor(0.1706) epoch: 136, step: 3\n",
      "loss: tensor(0.1663) epoch: 136, step: 4\n",
      "loss: tensor(0.1534) epoch: 136, step: 5\n",
      "loss: tensor(0.1451) epoch: 136, step: 6\n",
      "loss: tensor(0.1422) epoch: 136, step: 7\n",
      "Iteration :137\n",
      "loss: tensor(0.1082) epoch: 137, step: 0\n",
      "loss: tensor(0.1095) epoch: 137, step: 1\n",
      "loss: tensor(0.1125) epoch: 137, step: 2\n",
      "loss: tensor(0.1110) epoch: 137, step: 3\n",
      "loss: tensor(0.1116) epoch: 137, step: 4\n",
      "loss: tensor(0.1124) epoch: 137, step: 5\n",
      "loss: tensor(0.1189) epoch: 137, step: 6\n",
      "loss: tensor(0.1163) epoch: 137, step: 7\n",
      "Iteration :138\n",
      "loss: tensor(1.00000e-02 *\n",
      "       8.8094) epoch: 138, step: 0\n",
      "loss: tensor(0.1116) epoch: 138, step: 1\n",
      "loss: tensor(0.1156) epoch: 138, step: 2\n",
      "loss: tensor(0.1189) epoch: 138, step: 3\n",
      "loss: tensor(0.1181) epoch: 138, step: 4\n",
      "loss: tensor(0.1177) epoch: 138, step: 5\n",
      "loss: tensor(0.1102) epoch: 138, step: 6\n",
      "loss: tensor(0.1104) epoch: 138, step: 7\n",
      "Iteration :139\n",
      "loss: tensor(0.1148) epoch: 139, step: 0\n",
      "loss: tensor(0.1074) epoch: 139, step: 1\n",
      "loss: tensor(0.1112) epoch: 139, step: 2\n",
      "loss: tensor(0.1107) epoch: 139, step: 3\n",
      "loss: tensor(0.1151) epoch: 139, step: 4\n",
      "loss: tensor(0.1114) epoch: 139, step: 5\n",
      "loss: tensor(0.1082) epoch: 139, step: 6\n",
      "loss: tensor(0.1078) epoch: 139, step: 7\n",
      "Iteration :140\n",
      "loss: tensor(1.00000e-02 *\n",
      "       9.4644) epoch: 140, step: 0\n",
      "loss: tensor(0.1191) epoch: 140, step: 1\n",
      "loss: tensor(0.1180) epoch: 140, step: 2\n",
      "loss: tensor(0.1122) epoch: 140, step: 3\n",
      "loss: tensor(0.1135) epoch: 140, step: 4\n",
      "loss: tensor(0.1125) epoch: 140, step: 5\n",
      "loss: tensor(0.1104) epoch: 140, step: 6\n",
      "loss: tensor(0.1098) epoch: 140, step: 7\n",
      "Iteration :141\n",
      "loss: tensor(0.1077) epoch: 141, step: 0\n",
      "loss: tensor(0.1246) epoch: 141, step: 1\n",
      "loss: tensor(0.1239) epoch: 141, step: 2\n",
      "loss: tensor(0.1238) epoch: 141, step: 3\n",
      "loss: tensor(0.1374) epoch: 141, step: 4\n",
      "loss: tensor(0.1263) epoch: 141, step: 5\n",
      "loss: tensor(0.1191) epoch: 141, step: 6\n",
      "loss: tensor(0.1206) epoch: 141, step: 7\n",
      "Iteration :142\n",
      "loss: tensor(0.1029) epoch: 142, step: 0\n",
      "loss: tensor(0.1035) epoch: 142, step: 1\n",
      "loss: tensor(0.1002) epoch: 142, step: 2\n",
      "loss: tensor(1.00000e-02 *\n",
      "       9.6703) epoch: 142, step: 3\n",
      "loss: tensor(1.00000e-02 *\n",
      "       9.6962) epoch: 142, step: 4\n",
      "loss: tensor(0.1041) epoch: 142, step: 5\n",
      "loss: tensor(0.1007) epoch: 142, step: 6\n",
      "loss: tensor(0.1025) epoch: 142, step: 7\n",
      "Iteration :143\n",
      "loss: tensor(0.1329) epoch: 143, step: 0\n",
      "loss: tensor(0.1078) epoch: 143, step: 1\n",
      "loss: tensor(0.1075) epoch: 143, step: 2\n",
      "loss: tensor(0.1028) epoch: 143, step: 3\n",
      "loss: tensor(1.00000e-02 *\n",
      "       9.8996) epoch: 143, step: 4\n",
      "loss: tensor(1.00000e-02 *\n",
      "       9.7751) epoch: 143, step: 5\n",
      "loss: tensor(0.1013) epoch: 143, step: 6\n",
      "loss: tensor(0.1015) epoch: 143, step: 7\n",
      "Iteration :144\n",
      "loss: tensor(0.1098) epoch: 144, step: 0\n",
      "loss: tensor(1.00000e-02 *\n",
      "       9.7519) epoch: 144, step: 1\n",
      "loss: tensor(1.00000e-02 *\n",
      "       8.7720) epoch: 144, step: 2\n",
      "loss: tensor(1.00000e-02 *\n",
      "       9.3314) epoch: 144, step: 3\n",
      "loss: tensor(1.00000e-02 *\n",
      "       9.6196) epoch: 144, step: 4\n",
      "loss: tensor(1.00000e-02 *\n",
      "       9.6464) epoch: 144, step: 5\n",
      "loss: tensor(1.00000e-02 *\n",
      "       9.6703) epoch: 144, step: 6\n",
      "loss: tensor(1.00000e-02 *\n",
      "       9.8234) epoch: 144, step: 7\n",
      "Iteration :145\n",
      "loss: tensor(0.1342) epoch: 145, step: 0\n",
      "loss: tensor(1.00000e-02 *\n",
      "       9.5902) epoch: 145, step: 1\n",
      "loss: tensor(0.1048) epoch: 145, step: 2\n",
      "loss: tensor(0.1080) epoch: 145, step: 3\n",
      "loss: tensor(0.1021) epoch: 145, step: 4\n",
      "loss: tensor(1.00000e-02 *\n",
      "       9.9561) epoch: 145, step: 5\n",
      "loss: tensor(1.00000e-02 *\n",
      "       9.8853) epoch: 145, step: 6\n",
      "loss: tensor(1.00000e-02 *\n",
      "       9.7691) epoch: 145, step: 7\n",
      "Iteration :146\n",
      "loss: tensor(1.00000e-02 *\n",
      "       9.9486) epoch: 146, step: 0\n",
      "loss: tensor(1.00000e-02 *\n",
      "       9.9450) epoch: 146, step: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0.1197) epoch: 146, step: 2\n",
      "loss: tensor(0.1087) epoch: 146, step: 3\n",
      "loss: tensor(0.1095) epoch: 146, step: 4\n",
      "loss: tensor(0.1085) epoch: 146, step: 5\n",
      "loss: tensor(0.1132) epoch: 146, step: 6\n",
      "loss: tensor(0.1091) epoch: 146, step: 7\n",
      "Iteration :147\n",
      "loss: tensor(1.00000e-02 *\n",
      "       8.3614) epoch: 147, step: 0\n",
      "loss: tensor(1.00000e-02 *\n",
      "       9.1024) epoch: 147, step: 1\n",
      "loss: tensor(1.00000e-02 *\n",
      "       8.3988) epoch: 147, step: 2\n",
      "loss: tensor(1.00000e-02 *\n",
      "       8.4755) epoch: 147, step: 3\n",
      "loss: tensor(1.00000e-02 *\n",
      "       8.6783) epoch: 147, step: 4\n",
      "loss: tensor(1.00000e-02 *\n",
      "       9.0844) epoch: 147, step: 5\n",
      "loss: tensor(1.00000e-02 *\n",
      "       9.3902) epoch: 147, step: 6\n",
      "loss: tensor(1.00000e-02 *\n",
      "       9.1664) epoch: 147, step: 7\n",
      "Iteration :148\n",
      "loss: tensor(1.00000e-02 *\n",
      "       9.2115) epoch: 148, step: 0\n",
      "loss: tensor(1.00000e-02 *\n",
      "       7.9596) epoch: 148, step: 1\n",
      "loss: tensor(1.00000e-02 *\n",
      "       8.1472) epoch: 148, step: 2\n",
      "loss: tensor(0.1037) epoch: 148, step: 3\n",
      "loss: tensor(0.1048) epoch: 148, step: 4\n",
      "loss: tensor(0.1034) epoch: 148, step: 5\n",
      "loss: tensor(0.1027) epoch: 148, step: 6\n",
      "loss: tensor(1.00000e-02 *\n",
      "       9.9753) epoch: 148, step: 7\n",
      "Iteration :149\n",
      "loss: tensor(1.00000e-02 *\n",
      "       7.3536) epoch: 149, step: 0\n",
      "loss: tensor(1.00000e-02 *\n",
      "       7.6657) epoch: 149, step: 1\n",
      "loss: tensor(1.00000e-02 *\n",
      "       7.5833) epoch: 149, step: 2\n",
      "loss: tensor(1.00000e-02 *\n",
      "       8.2825) epoch: 149, step: 3\n",
      "loss: tensor(1.00000e-02 *\n",
      "       8.6177) epoch: 149, step: 4\n",
      "loss: tensor(1.00000e-02 *\n",
      "       8.7822) epoch: 149, step: 5\n",
      "loss: tensor(1.00000e-02 *\n",
      "       9.0636) epoch: 149, step: 6\n",
      "loss: tensor(1.00000e-02 *\n",
      "       9.2236) epoch: 149, step: 7\n",
      "Iteration :150\n",
      "loss: tensor(1.00000e-02 *\n",
      "       6.3366) epoch: 150, step: 0\n",
      "loss: tensor(1.00000e-02 *\n",
      "       7.3755) epoch: 150, step: 1\n",
      "loss: tensor(1.00000e-02 *\n",
      "       7.9103) epoch: 150, step: 2\n",
      "loss: tensor(1.00000e-02 *\n",
      "       8.1166) epoch: 150, step: 3\n",
      "loss: tensor(1.00000e-02 *\n",
      "       8.6267) epoch: 150, step: 4\n",
      "loss: tensor(1.00000e-02 *\n",
      "       8.7444) epoch: 150, step: 5\n",
      "loss: tensor(1.00000e-02 *\n",
      "       9.0720) epoch: 150, step: 6\n",
      "loss: tensor(1.00000e-02 *\n",
      "       8.9584) epoch: 150, step: 7\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, num_epochs+1):\n",
    "    epoch_loss = []\n",
    "    temp_avg=0\n",
    "    print(\"Iteration :\"+str(epoch))\n",
    "    \n",
    "    iteration=1;\n",
    "    \n",
    "    for step, (images, labels) in enumerate(trainLoader):\n",
    "        \n",
    "        im_arr = np.array(labels)\n",
    "        #print(\"Labels ==> \",np.unique(im_arr))\n",
    "        \n",
    "        im_arr[(im_arr!=0) & (im_arr!=15) & (im_arr!=40)] = 0\n",
    "        \n",
    "        # Set to classes\n",
    "        im_arr[im_arr==15] = 1\n",
    "        im_arr[im_arr==40] = 2\n",
    "        \n",
    "        inputs = Variable(images)\n",
    "        targets = Variable(torch.from_numpy(im_arr))\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss = criterion(outputs,targets[:,0])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss.append(loss.data[0])\n",
    "        \n",
    "        image = inputs[0].cpu().data\n",
    "        image[0] = image[0] * .229 + .485\n",
    "        image[1] = image[1] * .224 + .456\n",
    "        image[2] = image[2] * .225 + .406\n",
    "        \n",
    "        average = sum(epoch_loss) / len(epoch_loss)\n",
    "        temp_avg=temp_avg+average\n",
    "        \n",
    "        print(\"loss: \"+str(average)+\" epoch: \"+str(epoch)+\", step: \"+str(step))\n",
    "        iteration+=1\n",
    "    \n",
    "    avg_loss.append(temp_avg/iteration)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"PSPNetDeepLearningProject_new_2.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelLoaded = PSPNet(num_classes=3)\n",
    "modelLoaded.load_state_dict(torch.load(\"PSPNetDeepLearningProject_new_2.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PSPNet(\n",
       "  (resnet): MS_Deeplab(\n",
       "    (Scale): ResNet(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=True)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (6): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (7): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (8): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (9): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (10): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (11): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (12): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (13): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (14): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (15): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (16): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (17): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (18): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (19): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (20): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (21): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (22): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "      )\n",
       "      (layer5): Classifier_Module(\n",
       "        (conv2d_list): ModuleList(\n",
       "          (0): Conv2d(2048, 3, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))\n",
       "          (1): Conv2d(2048, 3, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12))\n",
       "          (2): Conv2d(2048, 3, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18))\n",
       "          (3): Conv2d(2048, 3, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (avgPool): AvgPool2d(kernel_size=14, stride=14, padding=0)\n",
       "  (layer5a): PSPModifierClass(\n",
       "    (features): Sequential(\n",
       "      (0): AvgPool2d(kernel_size=18, stride=18, padding=0)\n",
       "      (1): Conv2d(3, 5, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (2): BatchNorm2d(5, eps=1e-05, momentum=0.95, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): UpsamplingBilinear2d(size=18, mode=bilinear)\n",
       "    )\n",
       "  )\n",
       "  (layer5b): PSPModifierClass(\n",
       "    (features): Sequential(\n",
       "      (0): AvgPool2d(kernel_size=9, stride=9, padding=0)\n",
       "      (1): Conv2d(3, 5, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (2): BatchNorm2d(5, eps=1e-05, momentum=0.95, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): UpsamplingBilinear2d(size=18, mode=bilinear)\n",
       "    )\n",
       "  )\n",
       "  (layer5c): PSPModifierClass(\n",
       "    (features): Sequential(\n",
       "      (0): AvgPool2d(kernel_size=6, stride=6, padding=0)\n",
       "      (1): Conv2d(3, 5, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (2): BatchNorm2d(5, eps=1e-05, momentum=0.95, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): UpsamplingBilinear2d(size=18, mode=bilinear)\n",
       "    )\n",
       "  )\n",
       "  (layer5d): PSPModifierClass(\n",
       "    (features): Sequential(\n",
       "      (0): AvgPool2d(kernel_size=3, stride=3, padding=0)\n",
       "      (1): Conv2d(3, 5, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (2): BatchNorm2d(5, eps=1e-05, momentum=0.95, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): UpsamplingBilinear2d(size=18, mode=bilinear)\n",
       "    )\n",
       "  )\n",
       "  (final): Sequential(\n",
       "    (0): Conv2d(23, 25, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(25, eps=1e-05, momentum=0.95, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace)\n",
       "    (3): Dropout(p=0.1)\n",
       "    (4): Conv2d(25, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelLoaded.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'avg_loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-cf25aee71014>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mavg_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'avg_loss' is not defined"
     ]
    }
   ],
   "source": [
    "# len(avg_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "plt.title(\"Avg. Training loss for PSPNet vs Epochs\")\n",
    "\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Training Loss\")\n",
    "plt.plot(avg_loss)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Colorize1(object):\n",
    "    def __init__(self, n=3):\n",
    "        self.cmap = labelcolormap(3)\n",
    "        self.cmap = torch.from_numpy(self.cmap[:n])\n",
    "\n",
    "    def __call__(self, gray_image):\n",
    "        size = gray_image.size()\n",
    "        print(\"size of gray image \",size)\n",
    "        color_image = torch.ByteTensor(size[0], size[1]).fill_(0)\n",
    "\n",
    "        for label in range(0, len(self.cmap)):\n",
    "            mask = (label == gray_image[0]).cpu()\n",
    "            color_image[0][mask] = self.cmap[label][0]\n",
    "            color_image[1][mask] = self.cmap[label][1]\n",
    "            color_image[2][mask] = self.cmap[label][2]\n",
    "\n",
    "        return color_image\n",
    "\n",
    "class Colorize:\n",
    "\n",
    "    def __init__(self, n=3):\n",
    "        #self.cmap = colormap(256)\n",
    "        self.cmap = colormap(136)\n",
    "        #self.cmap = colormap(3)\n",
    "        self.cmap[n] = self.cmap[-1]\n",
    "        self.cmap = torch.from_numpy(self.cmap[:n])\n",
    "\n",
    "    def __call__(self, gray_image):\n",
    "        size = gray_image.size()\n",
    "        print(\"size of gray image \",size)\n",
    "        color_image = torch.ByteTensor(3, size[2], size[3]).fill_(0)\n",
    "#         color_image = torch.ByteTensor(3, size[0], size[1]).fill_(0)\n",
    "        #color_image = torch.ByteTensor(136).fill_(0)\n",
    "        \n",
    "\n",
    "        \n",
    "        #color_image = torch.ByteTensor(3, size[0], size[1]).fill_(0)\n",
    "        #print(\"color_image shape \",color_image.shape)\n",
    "        #print(\"self.cmap shape \",self.cmap.shape)\n",
    "        for label in range(1, len(self.cmap)):\n",
    "            mask = (label == gray_image[0]).cpu()\n",
    "            #mask = torch.ByteTensor((label == gray_image[0]).cpu())\n",
    "            \n",
    "#             mask = gray_image[0] == label\n",
    "#             color_image[0][mask] = self.cmap[label][0]\n",
    "#             color_image[1][mask] = self.cmap[label][1]\n",
    "#             color_image[2][mask] = self.cmap[label][2]\n",
    "            print(\"Mask type \",type(mask))\n",
    "            print(\"color_image type \",type(color_image))\n",
    "            #print(\"Mask ==> \",mask.shape,\" label ==> \",label , \" label type ==> \",type(label))  \n",
    "#             color_image[0][mask] = self.cmap[label][0]\n",
    "#             color_image[1][mask] = self.cmap[label][1]\n",
    "#             color_image[2][mask] = self.cmap[label][2]\n",
    "\n",
    "            color_image[0].masked_fill_(mask[0], self.cmap[label][0])\n",
    "            color_image[1].masked_fill_(mask[1], self.cmap[label][1])\n",
    "            color_image[2].masked_fill_(mask[2], self.cmap[label][2])\n",
    "\n",
    "            #color_image.masked_fill_(mask,label)\n",
    "            #color_image[mask] = self.cmap[label]\n",
    "            \n",
    "#             color_image[0][mask] = self.cmap[label][0]\n",
    "#             color_image[1][mask] = self.cmap[label][1]\n",
    "#             color_image[2][mask] = self.cmap[label][2]\n",
    "\n",
    "        return color_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_transform1 = Colorize()\n",
    "image_transform1 = ToPILImage()\n",
    "\n",
    "input_transform1 = Compose([\n",
    "    CenterCrop(256),\n",
    "    CustomScale(136),\n",
    "    ToTensor(),\n",
    "    Normalize([.485, .456, .406], [.229, .224, .225]),\n",
    "])\n",
    "target_transform1 = Compose([\n",
    "    CenterCrop(256),\n",
    "    CustomScale(136),\n",
    "    ToLabel(),\n",
    "    Relabel(255, 2),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.zeros(1, 3, 136, 136).random_(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"type of x\" ,type(x))\n",
    "# color = color_transform1(x)\n",
    "\n",
    "# #plt.imshow(x[0].numpy().transpose(1, 2, 0))\n",
    "# plt.imshow(color.numpy().transpose(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PSPNet(\n",
       "  (resnet): MS_Deeplab(\n",
       "    (Scale): ResNet(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=True)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (6): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (7): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (8): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (9): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (10): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (11): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (12): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (13): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (14): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (15): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (16): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (17): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (18): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (19): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (20): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (21): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (22): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace)\n",
       "        )\n",
       "      )\n",
       "      (layer5): Classifier_Module(\n",
       "        (conv2d_list): ModuleList(\n",
       "          (0): Conv2d(2048, 3, kernel_size=(3, 3), stride=(1, 1), padding=(6, 6), dilation=(6, 6))\n",
       "          (1): Conv2d(2048, 3, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12))\n",
       "          (2): Conv2d(2048, 3, kernel_size=(3, 3), stride=(1, 1), padding=(18, 18), dilation=(18, 18))\n",
       "          (3): Conv2d(2048, 3, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (avgPool): AvgPool2d(kernel_size=14, stride=14, padding=0)\n",
       "  (layer5a): PSPModifierClass(\n",
       "    (features): Sequential(\n",
       "      (0): AvgPool2d(kernel_size=18, stride=18, padding=0)\n",
       "      (1): Conv2d(3, 5, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (2): BatchNorm2d(5, eps=1e-05, momentum=0.95, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): UpsamplingBilinear2d(size=18, mode=bilinear)\n",
       "    )\n",
       "  )\n",
       "  (layer5b): PSPModifierClass(\n",
       "    (features): Sequential(\n",
       "      (0): AvgPool2d(kernel_size=9, stride=9, padding=0)\n",
       "      (1): Conv2d(3, 5, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (2): BatchNorm2d(5, eps=1e-05, momentum=0.95, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): UpsamplingBilinear2d(size=18, mode=bilinear)\n",
       "    )\n",
       "  )\n",
       "  (layer5c): PSPModifierClass(\n",
       "    (features): Sequential(\n",
       "      (0): AvgPool2d(kernel_size=6, stride=6, padding=0)\n",
       "      (1): Conv2d(3, 5, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (2): BatchNorm2d(5, eps=1e-05, momentum=0.95, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): UpsamplingBilinear2d(size=18, mode=bilinear)\n",
       "    )\n",
       "  )\n",
       "  (layer5d): PSPModifierClass(\n",
       "    (features): Sequential(\n",
       "      (0): AvgPool2d(kernel_size=3, stride=3, padding=0)\n",
       "      (1): Conv2d(3, 5, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (2): BatchNorm2d(5, eps=1e-05, momentum=0.95, affine=True, track_running_stats=True)\n",
       "      (3): ReLU(inplace)\n",
       "      (4): UpsamplingBilinear2d(size=18, mode=bilinear)\n",
       "    )\n",
       "  )\n",
       "  (final): Sequential(\n",
       "    (0): Conv2d(23, 25, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(25, eps=1e-05, momentum=0.95, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace)\n",
       "    (3): Dropout(p=0.1)\n",
       "    (4): Conv2d(25, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelLoaded.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataset-1.0/'+'images/060_resize.png', 'rb') as f:\n",
    "    image1 = Image.open(f).convert('RGB')\n",
    "\n",
    "image1 = input_transform(image1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.unique(image1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_transform(image1).save(\"temp_input_image.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/lib/python3.5/site-packages/ipykernel_launcher.py:1: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/home/cs18mtech01004/.local/lib/python3.5/site-packages/torch/nn/modules/upsampling.py:221: UserWarning: nn.UpsamplingBilinear2d is deprecated. Use nn.Upsample instead.\n",
      "  warnings.warn(\"nn.UpsamplingBilinear2d is deprecated. Use nn.Upsample instead.\")\n",
      "/home/cs18mtech01004/.local/lib/python3.5/site-packages/torch/nn/functional.py:1820: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.upsample instead.\n",
      "  warnings.warn(\"nn.functional.upsample_bilinear is deprecated. Use nn.functional.upsample instead.\")\n"
     ]
    }
   ],
   "source": [
    "output_label1 = modelLoaded(Variable(image1, volatile=True).unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = output_label1.data.max(1)[1].cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[2, 2, 2, ..., 2, 2, 2],\n",
       "        [2, 2, 2, ..., 2, 2, 2],\n",
       "        [2, 2, 2, ..., 2, 2, 2],\n",
       "        ..., \n",
       "        [2, 2, 2, ..., 2, 2, 2],\n",
       "        [2, 2, 2, ..., 2, 2, 2],\n",
       "        [2, 2, 2, ..., 2, 2, 2]]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ground truth\n",
    "\n",
    "with open('dataset-1.0/'+'annotations/060_annotation_resize.png', 'rb') as f:\n",
    "    ground_truth1 = Image.open(f).convert('P')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth1 = target_transform1(ground_truth1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_arr = np.array(ground_truth1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0 11 12 13 14 15 16 21 22 23 24 28 34 40]\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(ground_truth_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # label1 = color_transform(label[0].max(0)[1])\n",
    "\n",
    "# ground_truth_arr[ground_truth_arr==40].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp_output_label1=output_label1[0].data.max(0)[1]\n",
    "\n",
    "temp_output_label1=output_label1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.15129995, -2.11343932, -2.05899692, ...,  4.47049999,\n",
       "        4.5433321 ,  4.5617919 ], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# temp_output_label1[temp_output_label1==2].shape\n",
    "np.unique(temp_output_label1.data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_output_label1_np = temp_output_label1.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.5617919"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.amax(temp_output_label1_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.1513"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.amin(temp_output_label1_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(299,)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_output_label1_np[temp_output_label1_np>3.5].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_output_label1_np[np.logical_and(temp_output_label1_np>=1,temp_output_label1_np<=3.5)]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8121,)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_output_label1_np[temp_output_label1_np==0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_output_label1_np[temp_output_label1_np>3.5]=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(299,)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_output_label1_np[temp_output_label1_np==2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.15129995, -2.11343932, -2.05899692, ...,  0.9998517 ,\n",
       "        0.99994236,  2.        ], dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(temp_output_label1_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_output_label1_np[temp_output_label1_np==1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(299,)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_output_label1_np[temp_output_label1_np==2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_output_label1_np[temp_output_label1_np<=0]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30145,)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_output_label1_np[temp_output_label1_np==0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#temp_output_label1_np[temp_output_label1_np==np.amax(temp_output_label1_np)]=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp_output_label1_np[temp_output_label1_np==np.amin(temp_output_label1_np)]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(299,)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_output_label1_np[temp_output_label1_np==2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_output_label2 = torch.from_numpy(temp_output_label1_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of gray image  torch.Size([1, 3, 136, 136])\n",
      "Mask type  <class 'torch.Tensor'>\n",
      "color_image type  <class 'torch.Tensor'>\n",
      "Mask type  <class 'torch.Tensor'>\n",
      "color_image type  <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "temp1 = color_transform1(temp_output_label2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_image1 = image_transform(temp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_image1.save('output1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
